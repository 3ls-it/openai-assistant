#!/usr/bin/env python3
"""
openai-assistant v2
Copyright 2025 J Adams jfa63[at]duck[dot]com
Released under the 2-Clause BSD license.
"""
__version__ = 'v2.0.1'
__author__ = 'J. Adams jfa63[at]duck[dot]com'

# Builtin imports
import asyncio
from datetime import datetime
import os
from pathlib import Path
import runpy
from time import sleep
import warnings

# OpenAI imports
import openai
from openai import OpenAI
from openai import AssistantEventHandler
from openai.types.vector_stores.vector_store_file_batch import VectorStoreFileBatch

# Importing overide for EventHandler
from typing_extensions import override

# Rich imports for output formatting
from rich import print

# Textual imports
from textual import events, on
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import VerticalScroll
from textual.widgets import Header, Footer, Markdown, TextArea




## Top-level functions -------- #
# Helper to load configuration settings
def load_settings() -> dict:
    """
    Returns a configuration dictionary.
    """
    if CONFIG_PATH.is_file():
        return runpy.run_path(str(CONFIG_PATH))
    return {}
# End load_settings()


# Helper to update a single key in ~/.openai/settings.py
def write_setting(key: str, val) -> None:
    """
    Writes a single key entry to settings file
    """
    lines = []
    found = False
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        for line in f:
            if line.startswith(f"{key} ="):
                # overwrite the existing line
                if isinstance(val, str):
                    lines.append(f"{key} = '{val}'\n")
                else:
                    lines.append(f"{key} = {val}\n")
                found = True
            else:
                lines.append(line)
    if not found:
        # append at end
        if isinstance(val, str):
            lines.append(f"{key} = '{val}'\n")
        else:
            lines.append(f"{key} = {val}\n")
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        f.writelines(lines)
# End write_setting()


# Helper to set-up/check initial configuration
def config_app() -> None:
    """
    Sets up initial run configuration|checks exsisting configuration.
    """
    # Required and optional settings
    REQUIRED  = ("MODEL", "TEMP", "YOUR_NAME", "ASSISTANT_NAME", "OPENAI_API_KEY")
    DEFAULTS  = {"MODEL": "gpt-4.1", "TEMP": 0.3, "YOUR_NAME": "User", "ASSISTANT_NAME": "OpenAI"}
    OPTIONAL  = ("FURTHER_INSTRUCTIONS", "VECTOR_STORE_ID", "ASSISTANT_ID")

    # Prompt for missing required settings
    updated  = False
    for key in REQUIRED:
        if key not in settings or (key == "OPENAI_API_KEY" and not settings.get(key)):
            if key in DEFAULTS:
                settings[key] = DEFAULTS[key]
                print(f"No {key} found. Using default: {settings[key]}")
            else:
                settings[key] = input(f"Enter {key}: ").strip()
            updated = True

    # Ensure optional settings exist
    for key in OPTIONAL:
        if key not in settings:
            settings[key] = ""
            updated = True

    # Write settings file if needed
    if updated or not CONFIG_PATH.exists():
        CONFIG_DIR.mkdir(parents=True, exist_ok=True)
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            f.write("# ~/.openai/settings.py  (auto-generated by openai-assistant)\n")
            for key in REQUIRED + OPTIONAL:
                val = settings[key]
                if isinstance(val, str):
                    f.write(f"{key} = '{val}'\n")
                else:
                    f.write(f"{key} = {val}\n")
        print(f"Wrote settings to {CONFIG_PATH}")
# End config_app() 



## Helper Classes -------- #
# Text input widget
class Input_TextArea(TextArea):
    """
    Encapsulates a TextArea widget for user input
    """
    def _on_submit(self) -> str:
        return self.text
# End Class Input_TextArea


# Widget for displaying user input
class DisplayPrompt(Markdown):
    """
    Encapsulates a Markdown widget for user input display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Prompt 


# Widget for displaying OpenAI responses 
class DisplayResponse(Markdown):
    """
    Encapsulates a Markdown widget for LLM response display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Response


# Extend the EventHandler class 
class EventHandler(AssistantEventHandler):
    """
    Extend the EventHandler class overriding two methods
    to handle the events in the response stream.
    Added text attribute to collect text deltas
    """
    def __init__(self):
        # Initialize handler to set up internal state
        super().__init__()
        # Accumulate streamed text 
        self.text = ''

    @override
    def on_text_created(self, text) -> None:
        pass

    @override
    def on_text_delta(self, delta, snapshot):
        resp = str(delta.value)
        # Concatenate deltas for display.
        self.text += resp

    def on_tool_call_created(self, tool_call):
        lf.write(f'\n> {tool_call.type}\n')
        
    # For now we just write the input, output and logs to
    # ~/.openai/chat_log.txt
    def on_tool_call_delta(self, delta, snapshot):
        if delta.type == 'code_interpreter':
            if delta.code_interpreter.input:
                lf.write(delta.code_interpreter.input)
            if delta.code_interpreter.outputs:
                lf.write('\n\nOutput >')
                for output in delta.code_interpreter.outputs:
                    if output.type == 'logs':
                        lf.write(f'\n{output.logs}')
# End Class EventHandler


class Openai_API():
    """
    Encapsulates an OpenAI client instance.
    """
    # Turn off DepricationWarnings
    # We know Assistans API is to be depricated in 2026 
    warnings.filterwarnings("ignore", category=DeprecationWarning)

    def __init__(self, config):
        self.config = config
        self.api_key = self.config["OPENAI_API_KEY"]
        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.your_name = self.config["YOUR_NAME"]
        self.gpt_model = self.config["MODEL"]
        self.temp = self.config["TEMP"]
        self.client = OpenAI(api_key=self.api_key)
        self.assistant = None
        self.vector_store = None
        self.thread = None


    # Upload file to OpenAI account
    def file_upload(self, filename: str) -> VectorStoreFileBatch:
        """
        Uploads a file.
        """
        # Skip if the file is empty or missing
        if not os.path.isfile(filename) or os.path.getsize(filename) == 0:
            # Return a 'fake' VectorStoreFileBatch 
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 1,
                                                     'completed': 0,
                                                     'failed': 0,
                                                     'in_progress': 0,
                                                     'total': 0
                                                    },
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="cancelled")

        file_paths = [filename]
        file_streams = [open(path, "rb") for path in file_paths]

        # Upload files to the vector store
        file_batch = self.client.vector_stores.file_batches.upload_and_poll(
            vector_store_id=self.vector_store.id, files=file_streams
        )

        for fs in file_streams:
            fs.close()

        return file_batch
    # End file_upload()


    def setup(self) -> VectorStoreFileBatch:
        """
        Creates Assistant instance and Vector Store.
        """
        ## Assistant setup
        # Default baseline instructions 
        # Further, custom instructions can be added in
        # ~/.openai/settings.py
        instructions = f"You are {self.assistant_name}, {self.your_name}'s personal AI assistant."

        if self.config.get("ASSISTANT_ID"):
         self.assistant = self.client.beta.assistants.retrieve(
             assistant_id=self.config["ASSISTANT_ID"]
         )
        else:
         # Prompt for assistant creation
         print("No ASSISTANT_ID found. Creating new assistant...")
         self.assistant = self.client.beta.assistants.create(
             instructions=instructions,
             name=self.assistant_name,
             tools=[{"type": "code_interpreter"}, {"type": "file_search"}],
             model=self.gpt_model,
             temperature=self.temp
         )
         print(f"Created new assistant with ID {self.assistant.id}")
         resp = input("Save ASSISTANT_ID to config? [Y/n] ").strip().lower()
         if resp in ("", "y", "yes"):
             write_setting("ASSISTANT_ID", self.assistant.id)
             print("Updated ASSISTANT_ID in config.")
         else:
             print("ASSISTANT_ID not saved; will create new next run.")

        ## Vector Store setup
        if self.config.get("VECTOR_STORE_ID"):
         self.vector_store = self.client.vector_stores.retrieve(
             vector_store_id=self.config["VECTOR_STORE_ID"]
         )
        else:
         print("No VECTOR_STORE_ID found. Creating new vector store...")
         self.vector_store = self.client.vector_stores.create(name="Chat History")
         print(f"Created new vector store with ID {self.vector_store.id}")
         resp = input("Save VECTOR_STORE_ID to config? [Y/n] ").strip().lower()
         if resp in ("", "y", "yes"):
             write_setting("VECTOR_STORE_ID", self.vector_store.id)
             print("Updated VECTOR_STORE_ID in config.")
         else:
             print("VECTOR_STORE_ID not saved; will create new next run.")

        ## Upload chat_log.txt
        upload = self.file_upload(logfile)

        ## Update assistant with vector store
        self.assistant = self.client.beta.assistants.update(
         assistant_id=self.assistant.id,
         tool_resources={"file_search": {"vector_store_ids": [self.vector_store.id]}},
        )

        ## Create thread
        self.thread = self.client.beta.threads.create()
        return upload
    # End setup() 


    def send_query(self, query: str) -> str:
        """
        Creates a query message, submits to the API, streams response
        then returns resp as a string.
        """
        resp = ''
        try:
            ## Create a message from the user query.
            self.client.beta.threads.messages.create(
                    thread_id=self.thread.id,
                    role="user",
                    content=query
            )

            ## Then, we use the `stream` SDK helper
            # with the `EventHandler` class to create the Run
            # and stream the response.
            with self.client.beta.threads.runs.stream(
                    thread_id=self.thread.id,
                    assistant_id=self.assistant.id,
                    event_handler=EventHandler(),
                ) as stream:
                        stream.until_done()
                        resp = stream.text

        except openai.APIConnectionError as e:
            lf.write(str(e))  # an underlying Exception, likely raised within httpx.
            return "The server could not be reached. Check log."
        except openai.RateLimitError as e:
            lf.write(str(e))
            return "A 429 status code was received; we should back off a bit."
        except openai.APIStatusError as e:
            lf.write(str(e.status_code))
            lf.write(str(e.response))
            return "A non-200-range status code was received. Check log."
        # End try
        return resp
    # End send_query() 
# End Class Openai_API 


# App Class -------- #
class OpenaiAssistant(App):
    """
    Openai-Assistant application class.
    """

    def __init__(self, api, config, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.api = api
        self.config = config
        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.your_name = self.config["YOUR_NAME"]


    TITLE = "Openai Assistant"
    SUB_TITLE = f"{__version__}"
    AUTO_FOCUS = "Input_TextArea"

    # Style sheets for widgets 
    CSS = """
    DisplayPrompt {
        border: round cyan;
        background: $primary 10%;
        color: $text;
        margin: 1;        
        margin-right: 4;
        padding: 1 2 0 2;
    }

    DisplayResponse {
        border: round #f5d676;
        background: gray 10%;   
        color: $text;             
        margin: 1;      
        margin-left: 4; 
        padding: 1 2 0 2;
    }

    Input_TextArea {
        height: 20%;
    }
    """

    # Key bindings for Footer and help panel 
    BINDINGS = [
        Binding(key="ctrl+backslash", action="submit", description="Submit Input"),
        Binding(key="ctrl+q", action="quit", description="Quit"),
    ]

    # Create input widget and chat display widget
    input_area = Input_TextArea()
    chat_view = VerticalScroll()



    # Methods -------- #
    def on_mount(self) -> None:
        """
        Sets default theme.
        """
        self.theme = "flexoki"
    # End on_mount() 


    def compose(self) -> ComposeResult:
        """
        Composes UI elements.
        """
        resp_area = DisplayResponse(f"How can I help you {self.your_name}?",
                                    border_title=self.assistant_name)
        yield Header(show_clock=True)
        with self.chat_view:
            yield resp_area
        yield self.input_area
        yield Footer()
    # End compose() 


    @on(events.Key)
    async def on_key(self, event: events.Key) -> None:
        """
        The keystroke clrl+backslash submits user input to the API,
        then displays returned result.
        """
        if event.key == "ctrl+backslash":
            text = self.input_area._on_submit()
            if not text:
                return

            lf.write("\nMe:\n"+text+"\n\n")
            self.input_area.load_text("Thinking...")
            await self.chat_view.mount(
                    DisplayPrompt(text,
                                  border_title=self.your_name))

            resp = await asyncio.to_thread(self.api.send_query, text)
            lf.write("\n"+self.assistant_name+":\n"+resp+"\n\n")

            await self.chat_view.mount(
                    DisplayResponse(resp,
                                    border_title=self.assistant_name))
            self.input_area.clear()
            lf.flush()
    # End on_key() 
# End Class OpenaiAssistant



if __name__ == "__main__":
    # Clear terminal
    os.system('clear')
    print(f"\n[#f5d676 b]Openai Assistant {__version__}[/]\n")
    print("[green]Initialising settings and backend...[/]\n")

    # Get current date and time
    now = datetime.now()
    # Format as '9 June 2025 9:52pm'
    tstamp = now.strftime('%-d %B %Y %-I:%M%p').lower()

    ## Some global definitions
    # Define home directory and config paths
    homedir     = str(Path.home()) + "/"
    CONFIG_DIR  = Path(homedir) / ".openai"
    CONFIG_PATH = CONFIG_DIR / "settings.py"
    logfile = homedir + ".openai/chat_log.txt"

    # Get and load  settings, prompt for missing settings
    settings = load_settings()
    config_app()

    # Open log file in append mode
    lf = open(logfile, 'a', encoding='utf-8')

    # Initialise OpenAI client
    api = Openai_API(settings)

    # Set up configuration and upload chat_log.txt
    upload = api.setup()  # All CLI prompts and setup happen here
    status = upload.status.strip()
    if status == "cancelled":
        print("Not uploading empty chat log.")
    elif status == "completed":
        print(f"Uploaded [#d5d676]{logfile}[/]\n")
    else:
        print(f"Upload of [red]{logfile}[/] failed!\n")
    # a little time to read msg
    sleep(3)

    # Now launch the TUI, passing the API and settings objects
    app = OpenaiAssistant(api, settings)

    # Write timestamp to log file for session date
    lf.write(f"\nSession time stamp: {tstamp}\n")

    app.run()
