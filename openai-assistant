#!/usr/bin/env python3
"""
openai-assistant v2
Copyright 2025 J Adams jfa63[at]duck[dot]com
Released under the 2-Clause BSD license.
"""
__version__ = 'v2.3.0'
__author__ = 'J. Adams jfa63[at]duck[dot]com'

# Builtin imports
import argparse
import asyncio
import base64
from datetime import datetime
import logging
from logging.handlers import TimedRotatingFileHandler
import os
from pathlib import Path
import runpy
import subprocess as proc
import time
from time import sleep
import warnings

# OpenAI imports
import openai
from openai import AssistantEventHandler
from openai import OpenAI
from openai.types.vector_stores.vector_store_file_batch import VectorStoreFileBatch

# Importing overide for EventHandler
from typing_extensions import override

# Rich imports for text output formatting
from rich.console import Console
from rich import print

# Textual imports
from textual import events, on
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import Container, Grid, VerticalScroll
from textual.message import Message
from textual.reactive import reactive, var
from textual.screen import ModalScreen, Screen
import textual.widget 
from textual.widgets import (Button,
                             DirectoryTree,
                             Footer,
                             Header,
                             Input,
                             Label,
                             Markdown,
                             Static,
                             TextArea,
                            )



## Helper Classes -------- #
# Text input widget
class Input_TextArea(TextArea):
    """
    Encapsulates a TextArea widget for user input
    """
    #BORDER_TITLE = "Input"

    def _on_submit(self) -> str:
        return self.text
# End Class Input_TextArea


# Widget for displaying user input
class DisplayPrompt(Markdown):
    """
    Encapsulates a Markdown widget for user input display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Prompt 


# Widget for displaying OpenAI responses 
class DisplayResponse(Markdown):
    """
    Encapsulates a Markdown widget for LLM response display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Response


# Widget to display image generation status
class StatusWidget(Static):
    BORDER_TITLE = "Status"
#


# Modal Screen with quit dialogue  
class QuitDialogue(ModalScreen):
    """
    Provides a ModalScreen with a quit dialogue box.
    Based on example code from the Textual website.
    """

    def compose(self) -> ComposeResult:
        yield Grid(
            Label("Are you sure you want to quit?", id="message"),
            Button("Quit", variant="warning", compact=True, id="quit"),
            Button("Cancel", variant="primary", compact=True, id="cancel"),
            id="quit_dialogue",
        ) 
    # End compose() 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "quit":
            self.app.exit()
        else:
            self.app.pop_screen()
    # End on_button_pressed() 
# End Class QuitDialogue


# Modal Screen with upload dialogue  
class UploadDialogue(ModalScreen):
    """
    Provides a ModalScreen with the upload confirmation dialogue box.
    Based on example code from the Textual website.
    """

    def __init__(self, fname):
        super().__init__()
        self.fname = os.path.basename(fname)

    def compose(self) -> ComposeResult:
        yield Grid(
            Label(f"Upload {self.fname}?", id="message"),
            Button("Upload", variant="success", compact=True, id="upload"),
            Button("Cancel", variant="primary", compact=True, id="cancel"),
            id="upload_dialogue",
        ) 
    # End compose() 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "cancel":
            self.dismiss(False)
        elif event.button.id == "upload":
            self.dismiss(True)
    # End on_button_pressed() 
# End Class UploadDialogue


# Modal Screen with upload result 
class UploadResult(ModalScreen):
    """
    Provides a ModalScreen with the upload progress/result.
    """

    def __init__(self, path, status):
        super().__init__()
        self.path = os.path.basename(path)
        self.status = status
        self.dismiss_button = Button(
                "Dismiss",
                variant="primary",
                compact=True,
                disabled=False,
                id="dismiss"
                )


    def compose(self) -> ComposeResult:
        if self.status == "cancelled":
            msg = f"[yellowUpload of {self.path}[/] cancelled"
        elif self.status == "completed":
            msg = f"[green]Uploaded {self.path}[/]"
        elif self.status == "failed":
            msg = f"[red]Upload of {self.path} failed![/]"

        yield Grid(
            Label(msg, id="message"),
            self.dismiss_button,
            id="upload_result",
        ) 
    # End compose() 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "dismiss":
            self.app.pop_screen()
    # End on_button_pressed() 
# End Class UploadResult 


# Modal Screen for image dialogue  
class ImageDialogue(ModalScreen):
    """
    Provides a ModalScreen for image generation dialogue box.
    """
    def __init__(self):
        super().__init__()
        self.create_button = Button(
                "Create",
                variant="primary",
                compact=True,
                disabled=False,
                id="create")
        self.cancel_button = Button(
                "Cancel",
                variant="warning",
                compact=True,
                disabled=False,
                id="cancel")
    
    def compose(self):
        yield Grid(
            Label("Generate Image", id="message"),
            Label("Description:"),
            TextArea(placeholder="Describe image...", id="description_input"),
            Label("Save as:"),
            Input(placeholder="Filename", id="filename_input"),
            self.create_button,
            self.cancel_button,
            id="image_dialogue"
        )

    def on_mount(self):
        self.set_focus(self.query_one("#description_input", TextArea))

    def on_button_pressed(self, event):
        descr = self.query_one("#description_input", TextArea).text
        fname = self.query_one("#filename_input", Input).value
        fut = getattr(self.app, "_image_future", None)

        if event.button.id == "create":
            if os.path.exists(fname):
                self.app.notify(f"File '{fname}' already exists.", severity="warning")
                # Don't close, let the user correct the filename
                return
            if fut and not fut.done():
                fut.set_result((descr, fname))
            self.app.pop_screen()
        elif event.button.id == "cancel":
            fut.set_result((None, None))
            self.app.pop_screen()
# End Class ImageDialogue


# Modal Screen with arbitrary message 
class AboutDialogue(ModalScreen):
    """
    Provides a ModalScreen with an info dialogue.
    Used for "About" when F1 is pressed.
    """

    def __init__(self, msg):
        super().__init__()
        self.msg = msg
        self.dismiss_button = Button(
                "Dismiss",
                variant="warning",
                compact=True,
                disabled=False,
                id="dismiss"
                )


    def compose(self) -> ComposeResult:
        yield Grid(
            Label(self.msg, id="message"),
            self.dismiss_button,
            id="info_dialogue",
        ) 
    # End compose() 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "dismiss":
            self.app.pop_screen()
    # End on_button_pressed() 
# End Class InfoDialogue 


class ChatFileSelected(Message):
    def __init__(self, sender, path, method):
        super().__init__()
        self.path = path
        self.method = method  # "left-click", "right-click" ^ "enter"
# End Class ChatFileSelected


class ChatDirectoryTree(DirectoryTree):

    #def __init__(self, path, *args, **kwargs):
    #    super().__init__(path, *args, **kwargs)

    async def on_directory_tree_file_selected(
                self, event: DirectoryTree.FileSelected
    ) -> None:
        event.stop()

    async def on_mouse_down(self, event: events.MouseEvent) -> None:
        event.stop()
        node_index = event.style.meta.get("node")
        if node_index is not None:
            node = self.get_node_at_line(node_index)
            path = node.data.path  # full path
            if event.button == 1:  # Left click
                self.post_message(ChatFileSelected(self, path, "left-click"))
            elif event.button == 3:  # Right click
                self.post_message(ChatFileSelected(self, path, "right-click"))

    async def on_key(self, event: events.Key) -> None:
        if event.key == "enter":
            node = self.cursor_node
            if node is not None:
                path = node.data.path
                self.post_message(ChatFileSelected(self, path, "enter"))
# End Class ChatDirectoryTree


class ShowChat(Markdown):
    """
    Encapsulates a Markdown widget for LLM response display
    """
    def __init__(self, text="", border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
# End Class ShowChat


class ChatBrowser(Screen):
    """
    Provides the screen for browsing/selecting previous
    chats.
    """

    BINDINGS = [("escape", "app.pop_screen", "Close screen")]

    file_label = Label("[green b]Select File[/]", id="file-label")
    show_chat = ShowChat()

    def compose(self) -> ComposeResult:
        self.show_chat.visible = True
        homedir = Path.home()
        dir_path = homedir / ".openai/chats/"

        yield Header()
        with Container():
            yield Label("")
            yield Label("[#f5d676 b]Chat Browser (ESC to quit)[/]")
            yield self.file_label
            yield Label("")
            yield self.show_chat
            yield ChatDirectoryTree(dir_path, id="chat-view")


    def on_chat_file_selected(self, event: ChatFileSelected) -> None:
        """
        Called when the user clicks on a chat file.
        """
        event.stop()
        meth = event.method
        path = str(event.path)
        chat_fname = os.path.basename(path)
        
        if meth == "left-click":
            with open(path, "rt") as f:
               content = f.read() 
            self.file_label.update(f"[blue b]{chat_fname}[/]")
            self.show_chat.update(content) 
        elif meth == "enter":
            self.app.upload_chat(path)
            self.app.pop_screen()
# End Class ChatBrowser


# Extend the EventHandler class 
class EventHandler(AssistantEventHandler):
    """
    Extend the EventHandler class overriding two methods
    to handle the events in the response stream.
    Added text attribute to collect text deltas
    """
    def __init__(self):
        # Initialize handler to set up internal state
        super().__init__()
        # Accumulate streamed text 
        self.text = ''

    @override
    def on_text_delta(self, delta, snapshot):
        resp = str(delta.value)
        # Concatenate deltas for display.
        self.text += resp

    def on_tool_call_created(self, tool_call):
        try:
            if lf:
                lf.write(f'\n> {tool_call.type}\n')
        except Exception as e:
            print(f"[red]Log write error in on_tool_call_created():[/] {e}")
        
    # For now we just write the input, output and logs to
    # ~/.openai/chat_log.txt
    def on_tool_call_delta(self, delta, snapshot):
        try:
            if delta.type == 'code_interpreter':
                if delta.code_interpreter.input and lf:
                    lf.write(delta.code_interpreter.input)
                if delta.code_interpreter.outputs and lf:
                    lf.write('\n\nOutput >')
                    for output in delta.code_interpreter.outputs:
                        if output.type == 'logs':
                            lf.write(f'\n{output.logs}')
        except Exception as e:
            print(f"[red]Log write error in on_tool_call_delta():[/] {e}")
# End Class EventHandler


class Openai_API():
    """
    Encapsulates an OpenAI client instance.
    """
    # Turn off DepricationWarnings
    # We know Assistans API is to be depricated in 2026 
    warnings.filterwarnings("ignore", category=DeprecationWarning)

    def __init__(self, config, logger=None):
        self.config = config
        self.api_key = self.config["OPENAI_API_KEY"]
        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.your_name = self.config["YOUR_NAME"]
        self.gpt_model = self.config["MODEL"]
        self.temp = self.config["TEMP"]
        self.client = OpenAI(api_key=self.api_key)
        self.assistant = None
        self.logger = logger or logging.getLogger("openai_assistant.api")
        self.vector_store = None
        self.thread = None


    # Upload file to OpenAI account
    def file_upload(self, filename: str) -> VectorStoreFileBatch:
        """
        Uploads a file.
        """
        if not os.path.isfile(filename) or os.path.getsize(filename) == 0:
            try:
                self.logger.info(f"upload skipped: empty or missing file {filename}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 1,
                                                     'completed': 0,
                                                     'failed': 0,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="cancelled")

        file_streams = []
        try:
            file_streams.append(open(filename, "rb"))
            try:
                self.logger.debug(f"uploading 1 file to vector_store_id={self.vector_store.id}")
            except Exception:
                pass
            file_batch = self.client.vector_stores.file_batches.upload_and_poll(
                vector_store_id=self.vector_store.id, files=file_streams
            )
            try:
                self.logger.info(f"upload status={file_batch.status} file_counts={file_batch.file_counts}")
            except Exception:
                pass
            return file_batch
        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except Exception as e:
            try:
                self.logger.error(f"Unexpected error during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        finally:
            for fs in file_streams:
                try:
                    fs.close()
                except Exception:
                    pass
    # End file_upload()


    def setup(self) -> None:
        """
        Creates Assistant instance and Vector Store.
        """
        ## Assistant setup
        # Compose baseline instructions and append any user-provided
        # additional guidance from settings (FURTHER_INSTRUCTIONS).
        instructions = f"You are {self.assistant_name}, {self.your_name}'s personal AI assistant."
        further = (self.config.get("FURTHER_INSTRUCTIONS") or "").strip()

        if further:
            instructions = f"{instructions}\n\n{further}"

        if self.config.get("ASSISTANT_ID"):
            self.assistant = self.client.beta.assistants.retrieve(
                             assistant_id=self.config["ASSISTANT_ID"])
            try:
                self.logger.info(f"assistant retrieved id={self.assistant.id} model={self.gpt_model}")
            except Exception:
                pass
        else:
            # Prompt for assistant creation
            print("No ASSISTANT_ID found. Creating new assistant...")
            self.assistant = self.client.beta.assistants.create(
                instructions=instructions,
                name=self.assistant_name,
                tools=[{"type": "code_interpreter"}, {"type": "file_search"}],
                model=self.gpt_model,
                temperature=self.temp
            )
            print(f"Created new assistant with ID {self.assistant.id}")

            try:
                self.logger.info(f"assistant created id={self.assistant.id} model={self.gpt_model}")
            except Exception:
                pass

            resp = input("Save ASSISTANT_ID to config? [Y/n] ").strip().lower()
            if resp in ("", "y", "yes"):
                write_setting("ASSISTANT_ID", self.assistant.id)
                print("Updated ASSISTANT_ID in config.")
            else:
                print("ASSISTANT_ID not saved; will create new next run.")

        ## Vector Store setup
        if self.config.get("VECTOR_STORE_ID"):
            self.vector_store = self.client.vector_stores.retrieve(
                vector_store_id=self.config["VECTOR_STORE_ID"]
            )
            try:
                self.logger.info(f"vector_store retrieved id={self.vector_store.id}")
            except Exception:
                pass
        else:
            print("No VECTOR_STORE_ID found. Creating new vector store...")
            self.vector_store = self.client.vector_stores.create(name="Chat History")
            print(f"Created new vector store with ID {self.vector_store.id}")
            try:
                self.logger.info(f"vector_store created id={self.vector_store.id}")
            except Exception:
                pass
            resp = input("Save VECTOR_STORE_ID to config? [Y/n] ").strip().lower()
            if resp in ("", "y", "yes"):
                write_setting("VECTOR_STORE_ID", self.vector_store.id)
                print("Updated VECTOR_STORE_ID in config.")
            else:
                print("VECTOR_STORE_ID not saved; will create new next run.")

        ## Update assistant with vector store and ensure instructions are in-sync
        update_kwargs = {
            "assistant_id": self.assistant.id,
            "tool_resources": {"file_search": {"vector_store_ids": [self.vector_store.id]}},
        }
        updated_instructions = False
        try:
            if (self.assistant.instructions or "") != instructions:
                update_kwargs["instructions"] = instructions
                updated_instructions = True
        except Exception:
            update_kwargs["instructions"] = instructions
            updated_instructions = True

        try:
            self.assistant = self.client.beta.assistants.update(**update_kwargs)
        except Exception as e:
            try:
                self.logger.warning(f"failed to update assistant resources/instructions: {e}")
            except Exception:
                pass
            try:
                if lf:
                    lf.write(str(e))
            except Exception:
                pass
            print("[red]Warning:[/] Failed to update assistant tool resources/instructions; proceeding without vector store update.")
        else:
            if updated_instructions:
                print("Synced assistant instructions with settings: [#f5d676]YOUR_NAME[/] and [#f5d676]FURTHER_INSTRUCTIONS[/].")
                try:
                    self.logger.info("Assistant instructions synced with settings")
                except Exception:
                    pass

        ## Create thread
        self.thread = self.client.beta.threads.create()
        try:
            self.logger.info(f"thread created id={self.thread.id}")
        except Exception:
            pass
    # End setup() 


    def send_query(self, query: str) -> str:
        """
        Creates a query message, submits to the API, streams response
        then returns resp as a string.
        """
        resp = ''
        try:
            ## Create a message from the user query.
            self.client.beta.threads.messages.create(
                thread_id=self.thread.id,
                role="user",
                content=query
            )

            ## Then, we use the `stream` SDK helper
            # with the `EventHandler` class to create the Run
            # and stream the response.
            try:
                self.logger.info("run started")
                start = time.time()
            except Exception:
                pass
            with self.client.beta.threads.runs.stream(
                thread_id=self.thread.id,
                assistant_id=self.assistant.id,
                event_handler=EventHandler(),
            ) as stream:
                stream.until_done()
                resp = stream.text
            try:
                elapsed = time.time() - start
                self.logger.info(f"run completed elapsed={elapsed:.2f}s resp_len={len(resp)}")
            except Exception:
                pass

        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError: {e}")
            except Exception:
                pass
            return "The server could not be reached. Check log."

        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError: {e}")
            except Exception:
                pass
            return "A 429 status code was received; we should back off a bit."

        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError: {e}")
            except Exception:
                pass
            return 'A non-200-range status code was received. Check log.'
        except Exception as e:
            try:
                self.logger.error(f"Unexpected error during run: {e}")
            except Exception:
                pass
            return 'An unexpected error occurred while streaming. Check log.'
        return resp
    # End send_query() 
# End Class Openai_API 


# App Class -------- #
class OpenaiAssistant(App):
    """
    Openai-Assistant application class.
    """

    def __init__(self, api, config, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.api = api
        self.config = config
        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.your_name = self.config["YOUR_NAME"]


    TITLE = "OpenAI Assistant"
    SUB_TITLE = f"{__version__}  •  Submit: Ctrl+\\  •  Quit: Ctrl+Q"
    AUTO_FOCUS = "Input_TextArea"
    #SCREENS = {'chat_browser': ChatBrowser}
    #chat_browser = ChatBrowser(homedir)

    # Key bindings for Footer and help panel 
    BINDINGS = [
        Binding(key="ctrl+backslash", action="submit", description="Submit Input"),
        Binding(key="ctrl+q", action="quit", description="Quit"),
        Binding(key="ctrl+b", action="toggle_file_view", description="Toggle File-Upload Browser"),
        Binding(key="f1", action="about", description="About"),
        Binding("f2", "push_screen('chat_browser')", "Browse Chats"),
        Binding(key="f3", action="gen_image", description="Generate Image"),
    ]

    #Hide file tree on start 
    show_tree = var(False)
    path: reactive[str | None] = reactive(None)
 
    # Create input widget and chat display widget
    input_area = Input_TextArea()
    chat_view = VerticalScroll()

    # Style sheets for widgets 
    CSS = """
    DisplayPrompt {
        border: round cyan;
        background: $primary 10%;
        color: $text;
        margin: 1;        
        margin-right: 4;
        padding: 1 2 0 2;
    }

    DisplayResponse {
        border: round #f5d676;
        background: gray 10%;   
        color: $text;             
        margin: 1;      
        margin-left: 4; 
        padding: 1 2 0 2;
    }

    Input_TextArea {
        border: round blue;
        height: 20%;
    }

    ShowChat {
        border: round #f5d676;
        height: 90%;
        overflow: auto;
    }

    StatusWidget {
        border: round #f5d676;
    }

    #tree-view {
        display: none;
        scrollbar-gutter: stable;
        overflow: auto;
        width: auto;
        height: 100%;
        dock: left;
    }

    #chat-view {
        scrollbar-gutter: stable;
        overflow: auto;
        width: auto;
        height: 100%;
        dock: left;
    }

    OpenaiAssistant.-show-tree #tree-view {
        display: block;
        max-width: 50%;
    }

    ChatBrowser.-show-tree #chat-view {
        display: block;
        max-width: 25%;
    }

    ChatBrowser {
        align: center middle;
    }

    QuitDialogue {
        align: center middle;
    }

    UploadDialogue {
        align: center middle;
    }

    UploadResult {
        align: center middle;
    }

    ImageDialogue {
        align: center middle;
    }

    AboutDialogue {
        align: center middle;
    }

    #quit_dialogue {
        grid-size: 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 40;
        height: 11;
        border: thick $background 80%;
        background: $surface;
    }

    #upload_dialogue {
        grid-size: 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 50;
        height: 10;
        border: thick $background 80%;
        background: $surface;
    }

    #upload_result {
        grid-size: 1 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 50;
        height: 10;
        border: thick $background 80%;
        background: $surface;
    }

    #info_dialogue {
        grid-size: 1 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 5;
        padding: 0 1;
        width: 50;
        height: 20;
        border: thick $background 80%;
        background: $surface;
    }

    #image_dialogue {
        grid-size: 1 7;
        grid-gutter: 1;
        grid-rows: 1fr 1fr 8fr 1fr 2fr 1fr 1fr;
        padding: 0 1;
        width: 60;
        height: 28;
        border: thick $background 80%;
        background: $surface;
    }

    #description_input {
        height: 10;
    }

    #message {
        column-span: 2;
        height: 1fr;
        width: 1fr;
        content-align: center middle;
    }

    #status {
        dock: bottom;
        background: $panel;
        color: $text;
        padding: 0;
    }

    Button {
        width: 100%;
    }
    """


    # Methods -------- #
    def on_mount(self) -> None:
        """
        Sets default theme.
        """
        self.theme = "flexoki"
        self.install_screen(ChatBrowser(), name='chat_browser')
    # End on_mount() 


    def compose(self) -> ComposeResult:
        """
        Composes UI elements.
        """
        path = homedir
        resp_area = DisplayResponse(
            f"Hello {self.your_name}, I’m ready to help! Just type your input below.\n\n"
             "Hints: Submit with `Ctrl+Backslash`, new line with `Enter`, quit with `Ctrl+Q`.\n"
             "Toggle widget focus with `Tab`",
            border_title=self.assistant_name,
        )
        yield Header(show_clock=True)
        with Container():
            with self.chat_view:
                yield resp_area
            yield self.input_area
            yield StatusWidget("", id="status")
            yield DirectoryTree(path, id="tree-view")
        yield Footer()
    # End compose() 


    @on(events.Key)
    async def on_key(self, event: events.Key) -> None:
        """
        The keystroke ctrl+backslash submits user input to the API,
        then displays returned result.
        """
        if event.key == "ctrl+backslash":
            text = self.input_area._on_submit()
            if not text:
                return
            try:
                if lf:
                    lf.write("\nMe:\n"+text+"\n\n")
            except Exception as e:
                self.notify(f"[red]Error writing user input to log: {e}",
                            title="Error Saving File!",
                            severity="error",
                            timeout=5)

            self.input_area.load_text("Thinking...")
            await self.chat_view.mount(
                DisplayPrompt(text,
                              border_title=self.your_name))
            resp = await asyncio.to_thread(self.api.send_query, text)
            try:
                if lf:
                    lf.write("\n"+self.assistant_name+":\n"+resp+"\n\n")
                    lf.flush()
            except Exception as e:
                self.notify(f"[red]Error writing AI response to log: {e}",
                            title="Error Saving File!",
                            severity="error",
                            timeout=5)
            await self.chat_view.mount(
                DisplayResponse(resp,
                                border_title=self.assistant_name))
            self.input_area.clear()
    # End on_key() 


    # Status widget helper method
    def show_status(self, message: str) -> None:
        status = self.query_one("#status", StatusWidget)
        status.update(message)


    def do_file_upload(self, path: str) -> None:
        result = self.api.file_upload(path)
        status = result.status.strip()
        uploaded = UploadResult(path, status)
        self.push_screen(uploaded)


    def upload_chat(self, path) -> None:
        self.notify(f"Upload {path}")


    def generate_image(self, descr, fname) -> None:
        response = self.api.client.responses.create(
            model = self.config["MODEL"],
            input = descr,
            tools=[{"type": "image_generation"}],
        )

        # Collect image data
        image_data = [
            output.result
            for output in response.output
            if output.type == "image_generation_call"
        ]

        # Save the image to a file
        if image_data:
            image_base64 = image_data[0]
            try:
                with open(fname, "wb") as f:
                    f.write(base64.b64decode(image_base64))
                proc.run(['display', fname])
            except Exception as e:
                self.notify(f"Saving {fname} failed.\n{e}",
                            title="Error Saving File!",
                            severity="error",
                            timeout=5)
    # End generate_image()


    def on_directory_tree_file_selected(
        self, event: DirectoryTree.FileSelected
    ) -> None:
        """
        Called when the user clicks a file in the directory tree.
        """
        event.stop()
        self.path = str(event.path)

        # Called when UploadDialogue is dismissed.
        def _check_upload(upload: bool | None) -> None:
            if upload:
                self.do_file_upload(self.path)
        # End

        upload_dialogue = UploadDialogue(self.path)
        self.push_screen(upload_dialogue, _check_upload)
    # End on_directory_tree_file_selected() 


    def watch_show_tree(self, show_tree: bool) -> None:
        """
        Called when show_tree is modified.
        """
        self.set_class(show_tree, "-show-tree")


    def action_gen_image(self) -> None:
        loop = asyncio.get_running_loop()
        self._image_future = loop.create_future()
        self.push_screen(ImageDialogue())
        # Callback function
        def _on_done(fut: asyncio.Future):
            try:
                descr, fname = fut.result()
            except Exception:
                descr, fname = None, None
            # Schedule the async function on the event loop
            asyncio.get_running_loop().call_soon_threadsafe(
                    lambda: asyncio.create_task(self._run_gen_image(descr, fname)))
        self._image_future.add_done_callback(_on_done)
    # Helper
    async def _run_gen_image(self, descr, fname):
        if (descr is not None) and (fname is not None):
            loop = asyncio.get_running_loop()
            # Show status
            self.show_status(f"Generating image {fname}")
            await asyncio.sleep(0)
            self.api.logger.debug("about to enter try block")

            # Run generate_image in a thread pool
            try:
                await loop.run_in_executor(
                        None,  # None = default ThreadPoolExecutor
                        self.generate_image, descr, fname)
                self.api.logger.info(f"Image generated: {fname}")
            except Exception as e:
                self.api.logger.error(f"Image generation failed:\n{e}")
                self.notify(f"Image generation failed:\n{e}", severity="error", timeout=5)
        else:
            self.api.logger.error("Did not get values/canceled")
            self.notify("Did not get values or canceled.", severity="error", timeout=5)

        self.show_status("")
    # End action_gen_image() and helper


    def action_toggle_file_view(self) -> None:
        """
        Called in response to key binding.
        """
        self.query_one("#tree-view", DirectoryTree).reload()
        self.show_tree = not self.show_tree


    def action_quit(self) -> None:
        """
        Action to display the quit dialogue.
        """
        self.push_screen(QuitDialogue())


    def action_about(self) -> None:
        """
        Action to display the info dialogue.
        """
        msg = f"""
      [#f5d676 b]OpenAI Assistant {__version__}[/]\n\n
Released under the Two-Clause BSD License\n
   (c) 2025 J. Adams jfa63atduckdotcom
        """
        self.push_screen(AboutDialogue(msg))
# End Class OpenaiAssistant



if __name__ == "__main__":

    # Helper to load configuration settings
    def load_settings() -> dict:
        """
        Returns a configuration dictionary.
        """
        if CONFIG_PATH.is_file():
            return runpy.run_path(str(CONFIG_PATH))

        return {}
    # End load_settings()


    # Helper to update a single key in ~/.openai/settings.py
    def write_setting(key: str, val) -> None:
        """
        Writes a single key entry to settings file
        """
        lines = []
        found = False
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            for line in f:
                if line.startswith(f"{key} ="):
                    # overwrite the existing line
                    if isinstance(val, str):
                        lines.append(f"{key} = '{val}'\n")
                    else:
                        lines.append(f"{key} = {val}\n")
                    found = True
                else:
                    lines.append(line)
        if not found:
            # append at end
            if isinstance(val, str):
                lines.append(f"{key} = '{val}'\n")
            else:
                lines.append(f"{key} = {val}\n")
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            f.writelines(lines)
    # End write_setting()


    # Helper to set-up/check initial configuration
    def config_app() -> None:
        """
        Sets up initial run configuration|checks exsisting configuration.
        """
        # Required and optional settings
        REQUIRED  = ("MODEL", "TEMP", "YOUR_NAME", "ASSISTANT_NAME", "OPENAI_API_KEY")
        DEFAULTS  = {"MODEL": "gpt-4.1", "TEMP": 0.3, "YOUR_NAME": "User", "ASSISTANT_NAME": "OpenAI"}
        OPTIONAL  = ("FURTHER_INSTRUCTIONS", "VECTOR_STORE_ID", "ASSISTANT_ID")

        # Prompt for missing required settings
        updated  = False
        for key in REQUIRED:
            if key not in settings or (key == "OPENAI_API_KEY" and not settings.get(key)):
                if key in DEFAULTS:
                    settings[key] = DEFAULTS[key]
                    print(f"No {key} found. Using default: {settings[key]}")
                else:
                    settings[key] = input(f"Enter {key}: ").strip()
                updated = True

        # Ensure optional settings exist
        for key in OPTIONAL:
            if key not in settings:
                settings[key] = ""
                updated = True

        # Write settings file if needed
        if updated or not CONFIG_PATH.exists():
            CONFIG_DIR.mkdir(parents=True, exist_ok=True)
            with open(CONFIG_PATH, "w", encoding="utf-8") as f:
                f.write("# ~/.openai/settings.py  (auto-generated by openai-assistant)\n")
                for key in REQUIRED + OPTIONAL:
                    val = settings[key]
                    if isinstance(val, str):
                        f.write(f"{key} = '{val}'\n")
                    else:
                        f.write(f"{key} = {val}\n")
            print(f"Wrote settings to {CONFIG_PATH}")
    # End config_app() 


    def cleanup_chat_files(directory, min_size_bytes=50):
        """
        Delete all files in the chats dir smaller than min_size_b bytes.
        This will clean out "empty" chat files left over from unused
        sessions.
        """

        for filename in os.listdir(directory):
            filepath = os.path.join(directory, filename)
            if os.path.isfile(filepath):
                if os.path.getsize(filepath) < min_size_bytes:
                    os.remove(filepath)
    # End cleanup_chat_files()


    # Clear terminal
    os.system('clear')
    print(f"\n[#f5d676 b u]OpenAI Assistant {__version__}[/]\n")

    c = Console()
    try:
        print("[green]Aquiring settings and configuration[/]")
        with c.status(""):
            sleep(1)
            # Get current date and time
            now = datetime.now()
            # Format as e.g. '9 June 2025 9:52pm'
            tstamp = now.strftime('%-d %B %Y %-I:%M%p')

            ## Some global definitions
            # Define home directory and config paths
            homedir     = str(Path.home()) + "/"
            CONFIG_DIR  = Path(homedir) / ".openai"
            CONFIG_PATH = CONFIG_DIR / "settings.py"
            logfile = homedir + f".openai/chats/{tstamp}_chat_log.txt"

            # CLI flags
            parser = argparse.ArgumentParser(
                prog="openai-assistant",
                description="Terminal client for the OpenAI Assistants API",
            )
            parser.add_argument(
                "--reset-assistant",
                action="store_true",
                help="Ignore and clear ASSISTANT_ID in settings before startup",
            )
            parser.add_argument(
                "--reset-store",
                action="store_true",
                help="Ignore and clear VECTOR_STORE_ID in settings before startup",
            )
            parser.add_argument(
                "--debug-api",
                action="store_true",
                help="Enable DEBUG level API logging to ~/.openai/api.log",
            )
            args = parser.parse_args()

            # Get and load  settings, prompt for missing settings
            settings = load_settings()

            # Apply resets if requested
            if args.reset_assistant:
                settings["ASSISTANT_ID"] = ""
                try:
                    write_setting("ASSISTANT_ID", "")
                    print("Reset ASSISTANT_ID in settings.")
                except Exception:
                    pass
            if args.reset_store:
                settings["VECTOR_STORE_ID"] = ""
                try:
                    write_setting("VECTOR_STORE_ID", "")
                    print("Reset VECTOR_STORE_ID in settings.")
                except Exception:
                    pass
            config_app()

            # Configure API logger
            api_logfile = homedir + ".openai/api.log"
            api_logger = logging.getLogger("openai_assistant.api")
            api_logger.setLevel(logging.DEBUG if args.debug_api else logging.INFO)
            handler = TimedRotatingFileHandler(api_logfile, when="midnight", backupCount=7, encoding="utf-8")
            handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
            if not any(getattr(h, "baseFilename", None) == handler.baseFilename for h in api_logger.handlers):
                api_logger.addHandler(handler)
            api_logger.info("startup: settings initialised")

            # Open chat log file in append mode
            lf = open(logfile, 'a', encoding='utf-8')


        print("[green]Connecting to OpenAI API endpoint[/]")
        with c.status(""):
            #sleep(1)
            # Initialise OpenAI client
            api = Openai_API(settings, logger=api_logger)
            # Log config summary (no secrets)
            try:
                api_logger.info("config: model="+str(settings.get('MODEL'))+" temp="+str(settings.get('TEMP'))+" assistant_id="+("yes" if settings.get('ASSISTANT_ID') else "no")+" vector_store_id="+("yes" if settings.get('VECTOR_STORE_ID') else "no"))
            except Exception:
                pass


        print("[green]Loading configuration[/]\n")
        # Set up configuration and upload chat_log.txt
        api.setup()  # All CLI prompts and setup happen here

        # Now launch the TUI, passing the API and settings objects
        app = OpenaiAssistant(api, settings)

        # Write timestamp to log file for session date
        lf.write(f"\nSession time stamp: {tstamp}\n")

        app.run()
        lf.close()
        cleanup_chat_files(CONFIG_DIR / "chats/")
    except Exception as e:
        c.print_exception(f"[red]Caught:[/] {e}")
# End main

