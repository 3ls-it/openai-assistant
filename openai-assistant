#!/usr/bin/env python3
"""
openai-assistant v3
Copyright 2025 J Adams jfa63[at]duck[dot]com
Released under the 2-Clause BSD license.
"""
__version__ = 'v3.0.1'
__author__ = 'J. Adams jfa63[at]duck[dot]com'

# Builtin imports
import argparse
import asyncio
import base64
from datetime import datetime
import logging
from logging.handlers import TimedRotatingFileHandler
import os
from pathlib import Path
import runpy
import subprocess as proc
import threading
import time
from time import sleep
#import warnings

# OpenAI imports
import openai
from openai import OpenAI
from openai.types.vector_stores.vector_store_file_batch import VectorStoreFileBatch

# Rich imports for text output formatting
from rich.console import Console
from rich import print

# Textual imports
from textual import events, on
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import Container, Grid, VerticalScroll
from textual.message import Message
from textual.reactive import reactive, var
from textual.screen import ModalScreen, Screen
from textual.widgets import (Button,
                             DirectoryTree,
                             Footer,
                             Header,
                             Label,
                             Markdown,
                             Static,
                             TextArea,
                            )



## Helper Classes -------- #
# Text input widget
class Input_TextArea(TextArea):
    """
    Encapsulates a TextArea widget for user input
    """
    def _on_submit(self) -> str:
        return self.text
# End Class Input_TextArea



# Widget for displaying user input
class DisplayPrompt(Markdown):
    """
    Encapsulates a Markdown widget for user input display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Prompt 



# Widget for displaying OpenAI responses 
class DisplayResponse(Markdown):
    """
    Encapsulates a Markdown widget for LLM response display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Response



# Widget to display status messages
class StatusWidget(Static):
    BORDER_TITLE = "Status"
#



# Modal Screen with quit dialogue  
class QuitDialogue(ModalScreen):
    """
    Provides a ModalScreen with a quit dialogue box.
    Based on example code from the Textual website.
    """

    def compose(self) -> ComposeResult:
        yield Grid(
            Label("Are you sure you want to quit?", id="message"),
            Button("Quit", variant="warning", compact=True, id="quit"),
            Button("Cancel", variant="primary", compact=True, id="cancel"),
            id="quit_dialogue",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "quit":
            self.app.exit()
        else:
            self.app.pop_screen()
# End Class QuitDialogue



# Modal Screen with upload dialogue  
class UploadDialogue(ModalScreen):
    """
    Provides a ModalScreen with the upload confirmation dialogue box.
    Based on example code from the Textual website.
    """

    def __init__(self, fname):
        super().__init__()
        self.fname = os.path.basename(fname)

    def compose(self) -> ComposeResult:
        yield Grid(
            Label(f"Upload {self.fname}?", id="message"),
            Button("Upload", variant="success", compact=True, id="upload"),
            Button("Cancel", variant="primary", compact=True, id="cancel"),
            id="upload_dialogue",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "cancel":
            self.dismiss(False)
        elif event.button.id == "upload":
            self.dismiss(True)
# End Class UploadDialogue



# Modal Screen with upload result 
class UploadResult(ModalScreen):
    """
    Provides a ModalScreen with the upload progress/result.
    """

    def __init__(self, path, status):
        super().__init__()
        self.path = os.path.basename(path)
        self.status = status
        self.dismiss_button = Button(
                "Dismiss",
                variant="primary",
                compact=True,
                disabled=False,
                id="dismiss"
                )

    def compose(self) -> ComposeResult:
        if self.status == "cancelled":
            msg = f"[yellowUpload of {self.path}[/] cancelled"
        elif self.status == "completed":
            msg = f"[green]Uploaded {self.path}[/]"
        elif self.status == "failed":
            msg = f"[red]Upload of {self.path} failed![/]"

        yield Grid(
            Label(msg, id="message"),
            self.dismiss_button,
            id="upload_result",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "dismiss":
            self.app.pop_screen()
# End Class UploadResult 



# Modal Screen with arbitrary message 
class AboutDialogue(ModalScreen):
    """
    Provides a ModalScreen with an info dialogue.
    Used for "About" when F1 is pressed.
    """

    def __init__(self, msg):
        super().__init__()
        self.msg = msg
        self.dismiss_button = Button(
                "Dismiss",
                variant="warning",
                compact=True,
                disabled=False,
                id="dismiss"
                )

    def compose(self) -> ComposeResult:
        yield Grid(
            Label(self.msg, id="message"),
            self.dismiss_button,
            id="info_dialogue",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "dismiss":
            self.app.pop_screen()
# End Class InfoDialogue 



class ChatFileSelected(Message):
    def __init__(self, sender, path, method):
        super().__init__()
        self.path = path
        self.method = method  # "left-click", "right-click" ^ "enter"
# End Class ChatFileSelected



class ChatDirectoryTree(DirectoryTree):
    async def on_directory_tree_file_selected(
                            self, event: DirectoryTree.FileSelected
    ) -> None:
        event.stop()

    async def on_mouse_down(self, event: events.MouseEvent) -> None:
        event.stop()
        node_index = event.style.meta.get("node")
        if node_index is not None:
            node = self.get_node_at_line(node_index)
            path = node.data.path  # full path
            if event.button == 1:  # Left click
                self.post_message(ChatFileSelected(self, path, "left-click"))
            elif event.button == 3:  # Right click
                self.post_message(ChatFileSelected(self, path, "right-click"))

    async def on_key(self, event: events.Key) -> None:
        if event.key == "enter":
            node = self.cursor_node
            if node is not None:
                path = node.data.path
                self.post_message(ChatFileSelected(self, path, "enter"))
# End Class ChatDirectoryTree



class ShowChat(Markdown):
    """
    Encapsulates a Markdown widget for chat file display
    """
    def __init__(self, text="", border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
# End Class ShowChat



class ChatBrowser(Screen):
    """
    Provides the screen for browsing/selecting previous
    chats.
    """
    def __init__(self, chats_dir, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.dir_path = chats_dir

    BINDINGS = [("escape", "app.pop_screen", "Close screen")]

    file_label = Label("[green b]Select File[/]", id="file-label")
    show_chat = ShowChat()


    def compose(self) -> ComposeResult:
        self.show_chat.visible = True

        yield Header()
        with Container():
            yield Label("")
            yield Label("[#f5d676 b]Chat Browser (ESC to quit)[/]")
            yield self.file_label
            yield Label("")
            yield self.show_chat
            yield ChatDirectoryTree(self.dir_path, id="chat-view")


    async def on_chat_file_selected(self, event: ChatFileSelected) -> None:
        """
        Called when the user clicks on a chat file.
        """
        event.stop()
        meth = event.method
        path = str(event.path)
        chat_fname = os.path.basename(path)
        
        if meth == "left-click":
            with open(path, "rt") as f:
               content = f.read() 
            self.file_label.update(f"[blue b]{chat_fname}[/]")
            self.show_chat.update(content) 
        elif meth == "enter":
            self.app.pop_screen()
            await self.app.continue_chat(path)
# End Class ChatBrowser



class Openai_API():
    """
    Encapsulates an OpenAI client instance.
    """

    def __init__(self, config, logger=None):
        self.config = config
        self.api_key = self.config["OPENAI_API_KEY"]
        self.prompt_id = self.config["PROMPT_ID"]
        self.gpt_model = self.config["MODEL"]
        self.temp = self.config["TEMP"]
        self.vector_store_id = self.config["VECTOR_STORE_ID"]
        self.client = OpenAI(api_key=self.api_key)
        self.logger = logger or logging.getLogger("openai_assistant.api")
        # server-side conversation object backing this chat session
        self.conversation_id = None
        # lock to prevent concurrent operation on conversation
        self._conversation_lock = threading.Lock()
        self.vector_store = None
        ## Vector Store setup        
        if self.vector_store_id:
            self.vector_store = self.client.vector_stores.retrieve(
                 vector_store_id=self.vector_store_id
            )
            try:
                self.logger.info(f"vector_store retrieved id={self.vector_store.id}")
            except Exception:
                pass


    def _ensure_conversation(self) -> None:
        """
        Create a Conversation for this chat session.
        """
        if self.conversation_id is not None:
            return

        conv = self.client.conversations.create(
            metadata={
                "app": "openai-assistant",
            }
        )

        self.conversation_id = conv.id
        self.logger.info(f"Created conversation {self.conversation_id}")


    def send_query(self, messages, lf=None,
                   images_dir=None, display_images=True) -> tuple[str, list[str]]:
        """
        Sends a query to the OpenAI Responses API.
        - messages: str or list of message dicts (see OpenAI docs)
        - lf: open file handle for logging (optional)
        - images_dir: directory to save images (required for image output)
        - display_images: if True, try to display images with `feh`
        Returns: (text_response, list_of_image_paths)
        """

        if isinstance(messages, str):
            messages = [{"role": "user", "content": messages}]

        # Make sure we have a Conversation backing this chat
        self._ensure_conversation()

        start = time.time()

        # small retry loop for conversation_locked
        max_retries = 3
        backoff = 1.0  # seconds

        try:
            for attempt in range(1, max_retries + 1):
                try:
                    with self._conversation_lock:
                        resp = self.client.responses.create(
                            model=self.gpt_model,
                            input=messages,
                            prompt={
                                "id": self.prompt_id
                            },
                            conversation=self.conversation_id,
                            tools=[{"type": "image_generation", "partial_images": 0}],
                        )
                    break  # success, exit retry loop

                except openai.APIStatusError as e:
                    # Check specifically for conversation_locked
                    msg = str(e)
                    cond1 = "conversation_locked"
                    cond2 = "Another process is currently operating on this conversation"
                    if cond1 in msg or cond2 in msg:
                        try:
                            self.logger.warning(
                                "conversation_locked for conversation %s (attempt %d/%d); retrying in %.1fs",
                                self.conversation_id,
                                attempt,
                                max_retries,
                                backoff,
                            )
                        except Exception:
                            pass
                        if attempt == max_retries:
                            # Give up after max_retries; re-raise to fall through to your generic handler
                            raise
                        time.sleep(backoff)
                        continue
                    # Not a conversation_locked error: re-raise and let outer except handle it
                    raise
            # end retry loop

            text = resp.output_text or ""
            image_paths = []

            if images_dir:
                os.makedirs(images_dir, exist_ok=True)

            # Walk the structured outputs for images.
            for item in resp.output:
                if item.type == "image_generation_call":
                    image_base64 = item.result  # base64-encoded PNG/WebP/JPEG
                    now = datetime.now()
                    image_fname = f"image_{now:%Y%m%d_%H%M%S_%f}.png"
                    if images_dir is None:
                        raise ValueError("images_dir must be specified to save images.")
                    image_path = os.path.join(images_dir, image_fname)

                    try:
                        with open(image_path, "wb") as f:
                            f.write(base64.b64decode(image_base64))
                        image_paths.append(image_path)
                    except Exception as e:
                        self.logger.error(f"Saving {image_fname} failed: {e}")

            # Log image names to the chat log, if any
            if lf and image_paths:
                for img in image_paths:
                    lf.write(f"[image] {img}\n")
                lf.flush()

            # Display images, if any
            if display_images and image_paths:
                for img in image_paths:
                    try:
                        # Use 'feh' if present
                        proc.Popen(['feh', img])
                    except Exception as e:
                        self.logger.error(f"[system] Unable to display image: {e}")

            try:
                elapsed = time.time() - start
                self.logger.info(
                    f"run completed elapsed={elapsed:.2f}s resp_items={len(resp.output)}"
                )
            except Exception:
                pass

            return text, image_paths

        # Log errros and notify on screen
        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError: {e}")
            except Exception:
                pass
            return "The server could not be reached. Check log.", []

        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError: {e}")
            except Exception:
                pass
            return "A 429 status code was received; we should back off a bit.", []

        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError: {e}")
            except Exception:
                pass
            return 'A non-200-range status code was received. Check log.', []

        except Exception as e:
            try:
                self.logger.exception(f"Unexpected error during run: {e}")
            except Exception:
                pass
            return 'An unexpected error occurred while streaming. Check log.', []
    # End send_query()


    # Upload file to OpenAI account
    def file_upload(self, filename: str) -> VectorStoreFileBatch:
        """
        Uploads a file.
        """
        if not os.path.isfile(filename) or os.path.getsize(filename) == 0:
            try:
                self.logger.info(f"upload skipped: empty or missing file {filename}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 1,
                                                     'completed': 0,
                                                     'failed': 0,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="cancelled")

        file_streams = []
        try:
            file_streams.append(open(filename, "rb"))
            try:
                self.logger.debug(f"uploading 1 file to vector_store_id={self.vector_store.id}")
            except Exception:
                pass
            file_batch = self.client.vector_stores.file_batches.upload_and_poll(
                vector_store_id=self.vector_store.id, files=file_streams
            )
            try:
                self.logger.info(f"upload status={file_batch.status} file_counts={file_batch.file_counts}")
            except Exception:
                pass
            return file_batch
        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except Exception as e:
            try:
                self.logger.error(f"Unexpected error during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        finally:
            for fs in file_streams:
                try:
                    fs.close()
                except Exception:
                    pass
    # End file_upload()
# End Class Openai_API 



# App Class -------- #
class OpenaiAssistant(App):
    """
    Openai-Assistant application class.
    """

    def __init__(self, config, config_dir, chats_dir,
                        images_dir, api_logger, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.config = config
        self.config_dir = config_dir
        self.chats_dir = chats_dir
        self.images_dir = images_dir

        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.user_name = self.config["YOUR_NAME"]

        # Create API instance
        self.api_logger = api_logger
        self.api = Openai_API(self.config, logger=self.api_logger)

        try:
            self.api_logger.info("config: model="+str(self.config.get('MODEL'))+ \
                " temp="+str(self.config.get('TEMP'))+ \
                " prompt_id="+("yes" if self.config.get('PROMPT_ID') else "no")+ \
                " vector_store_id="+("yes" if self.config.get('VECTOR_STORE_ID') else "no")
            )
        except Exception:
            pass

        # Chat log setup
        now = datetime.now()
        # Format as e.g. '9 June 2025 9:52pm'
        tstamp = now.strftime('%-d %B %Y %-I:%M%p')
        # No spaces in filename
        stamp = tstamp.replace(" ", "_")
        self.logfile = self.chats_dir / f"{stamp}-chat_log.txt"

        # Open chat log file in append mode
        self.lf = open(self.logfile, 'a', encoding='utf-8')
        # Write timestamp to log file for session date
        self.lf.write(f"\nSession time stamp: {tstamp}\n")
        self.lf.flush()
    # End constructor


    TITLE = "OpenAI Assistant"
    SUB_TITLE = f"{__version__}  •  Submit: Ctrl+\\  •  Quit: Ctrl+Q"
    AUTO_FOCUS = "Input_TextArea"

    # Key bindings for Footer and help panel 
    BINDINGS = [
        Binding(key="ctrl+backslash", action="submit", description="Submit Input"),
        Binding(key="ctrl+q", action="quit", description="Quit"),
        Binding(key="ctrl+b", action="toggle_file_view", description="Toggle File-Upload Browser"),
        Binding(key="f1", action="about", description="About"),
        Binding("f2", "push_screen('chat_browser')", "Browse/Continue Chats"),
    ]

    #Hide file tree on start 
    show_tree = var(False)
    path: reactive[str | None] = reactive(None)
 
    # Create input widget and chat display widget
    input_area = Input_TextArea()
    chat_view = VerticalScroll()

    # Style sheets for widgets 
    CSS = """
    DisplayPrompt {
        border: round cyan;
        background: $primary 10%;
        color: $text;
        margin: 1;        
        margin-right: 4;
        padding: 1 2 0 2;
    }

    DisplayResponse {
        border: round #f5d676;
        background: gray 10%;   
        color: $text;             
        margin: 1;      
        margin-left: 4; 
        padding: 1 2 0 2;
    }

    Input_TextArea {
        border: round blue;
        height: 20%;
    }

    ShowChat {
        border: round #f5d676;
        height: 90%;
        overflow: auto;
    }

    StatusWidget {
        border: round #f5d676;
    }

    #tree-view {
        display: none;
        scrollbar-gutter: stable;
        overflow: auto;
        width: auto;
        height: 100%;
        dock: left;
    }

    #chat-view {
        scrollbar-gutter: stable;
        overflow: auto;
        width: auto;
        height: 100%;
        dock: left;
    }

    OpenaiAssistant.-show-tree #tree-view {
        display: block;
        max-width: 50%;
    }

    ChatBrowser.-show-tree #chat-view {
        display: block;
        max-width: 25%;
    }

    ChatBrowser {
        align: center middle;
    }

    QuitDialogue {
        align: center middle;
    }

    UploadDialogue {
        align: center middle;
    }

    UploadResult {
        align: center middle;
    }

    AboutDialogue {
        align: center middle;
    }

    #quit_dialogue {
        grid-size: 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 40;
        height: 11;
        border: thick $background 80%;
        background: $surface;
    }

    #upload_dialogue {
        grid-size: 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 50;
        height: 10;
        border: thick $background 80%;
        background: $surface;
    }

    #upload_result {
        grid-size: 1 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 50;
        height: 10;
        border: thick $background 80%;
        background: $surface;
    }

    #info_dialogue {
        grid-size: 1 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 5;
        padding: 0 1;
        width: 50;
        height: 20;
        border: thick $background 80%;
        background: $surface;
    }

    #description_input {
        height: 10;
    }

    #message {
        column-span: 2;
        height: 1fr;
        width: 1fr;
        content-align: center middle;
    }

    #status {
        dock: bottom;
        background: $panel;
        color: $text;
        padding: 0;
    }

    Button {
        width: 100%;
    }
    """


    # Methods -------- #
    def on_mount(self) -> None:
        """
        Sets default theme.
        """
        self.theme = "flexoki"
        self.install_screen(ChatBrowser(self.chats_dir), name='chat_browser')


    def compose(self) -> ComposeResult:
        """
        Composes UI elements.
        """
        path = Path.home()
        resp_area = DisplayResponse(
            f"Hello {self.user_name}! Just type your input below.\n\n"
             "Hints: Submit with `Ctrl+Backslash`, new line with `Enter`, quit with `Ctrl+Q`.\n"
             "Toggle widget focus with `Tab`",
            border_title=self.assistant_name,
        )
        yield Header(show_clock=True)
        with Container():
            with self.chat_view:
                yield resp_area
            yield self.input_area
            yield StatusWidget("", id="status")
            yield DirectoryTree(path, id="tree-view")
        yield Footer()


    @on(events.Key)
    async def on_key(self, event: events.Key) -> None:
        """
        The keystroke ctrl+backslash submits user input to the API,
        then displays returned result.
        """
        if event.key == "ctrl+backslash":
            self.show_status("")
            text = self.input_area._on_submit()
            if not text:
                return
            try:
                if self.lf:
                    self.lf.write("\n[user] "+text+"\n\n")
            except Exception as e:
                self.notify(f"[red]Error writing user input to log: {e}",
                            title="Write Error!",
                            severity="error",
                            timeout=5)

            self.input_area.load_text("Thinking...")
            self.show_status("Sending query")
            await self.chat_view.mount(
                DisplayPrompt(text, border_title=self.user_name))

            start = time.time()
            resp, image_path = await asyncio.to_thread(
                    self.api.send_query, text, self.lf, self.images_dir)
            elapsed = time.time() - start

            has_text = bool(resp and resp.strip())
            if has_text:
                try:
                    if self.lf:
                        self.lf.write("\n[assistant] " + resp + "\n\n")
                        self.lf.flush()
                except Exception as e:
                    self.notify(
                        f"[red]Error writing AI response to log: {e}",
                        title="Error Saving File!",
                        severity="error",
                        timeout=5,
                    )

                await self.chat_view.mount(
                    DisplayResponse(resp, border_title=self.assistant_name)
                )

            self.input_area.clear()
            self.show_status(f"Run completed in {elapsed:.2f}s")
    # End on_key() 


    def on_directory_tree_file_selected(
        self, event: DirectoryTree.FileSelected
    ) -> None:
        """
        Called when the user clicks a file in the directory tree.
        """
        event.stop()
        self.path = str(event.path)

        # Called when UploadDialogue is dismissed.
        def _check_upload(upload: bool | None) -> None:
            if upload:
                self.do_file_upload(self.path)
        # End

        upload_dialogue = UploadDialogue(self.path)
        self.push_screen(upload_dialogue, _check_upload)


    def watch_show_tree(self, show_tree: bool) -> None:
        """
        Called when show_tree is modified.
        """
        self.set_class(show_tree, "-show-tree")


    # Status widget helper method
    def show_status(self, message: str) -> None:
        status = self.query_one("#status", StatusWidget)
        status.update(message)


    def do_file_upload(self, path: str) -> None:
        result = self.api.file_upload(path)
        status = result.status.strip()
        uploaded = UploadResult(path, status)
        self.push_screen(uploaded)


    async def continue_chat(self, chpath) -> None:
        # Create continuation prompt
        inst = """
        Here is a previous chat log. Please summarize the key points
        and continue the conversation from where it left off.
        """
        chname = os.path.basename(chpath)
        self.input_area.load_text("Thinking...")
        self.show_status(f"Loading chat: {chname}")

        with open(chpath, 'r', encoding="utf-8") as f:
            chat_history = f.read()
        prompt = f"{inst}\n\nChat log:\n{chat_history}"

        # Close existing log file
        self.lf.flush()
        self.lf.close()
        # Re-open selected chat
        now = datetime.now()
        tstamp = now.strftime('%-d %B %Y %-I:%M%p')
        self.lf = open(chpath, "a", encoding="utf-8")
        self.lf.write(f"\nContinuing session at: {tstamp}\n\n")
        self.lf.flush()

        # Send prompt and await response
        start = time.time()
        resp, _ = await asyncio.to_thread(
                self.api.send_query, prompt, self.lf, self.images_dir)
        elapsed = time.time() - start

        has_text = bool(resp and resp.strip())
        if has_text:
            try:
                if self.lf:
                    self.lf.write("\n[assistant] " + resp + "\n\n")
                    self.lf.flush()
            except Exception as e:
                self.notify(
                    f"[red]Error writing AI response to log: {e}",
                    title="Error Saving File!",
                    severity="error",
                    timeout=5,
                )

            await self.chat_view.mount(
                DisplayResponse(resp, border_title=self.assistant_name)
            )

        self.input_area.clear()
        self.show_status(f"Run completed in {elapsed:.2f}s")
    # End continue_chat


    def action_toggle_file_view(self) -> None:
        """
        Called in response to key binding.
        """
        self.query_one("#tree-view", DirectoryTree).reload()
        self.show_tree = not self.show_tree


    def action_quit(self) -> None:
        """
        Action to display the quit dialogue.
        """
        self.push_screen(QuitDialogue())


    def action_about(self) -> None:
        """
        Action to display the info dialogue.
        """
        msg = f"""
      [#f5d676 b]OpenAI Assistant {__version__}[/]\n\n
Released under the Two-Clause BSD License\n
   (c) 2025 J. Adams jfa63atduckdotcom
        """
        self.push_screen(AboutDialogue(msg))
# End Class OpenaiAssistant



class ConfigManager:
    """
    Encapsulates configuration management
    """
    def __init__(self, config_dir, config_path, chats_dir, images_dir):
        self.config_dir = config_dir
        self.config_path = config_path
        self.chats_dir = chats_dir
        self.images_dir = images_dir

    # Helper to load configuration settings
    def load_settings(self) -> dict:
        """
        Returns a configuration dictionary.
        """
        if self.config_path.is_file():
            return runpy.run_path(str(self.config_path))

        return {}
    # End load_settings()


    # Helper to update a single key in ~/.openai/settings.py
    def write_setting(self, key: str, val) -> None:
        """
        Writes a single key entry to settings file
        """
        lines = []
        found = False
        with open(self.config_path, "r", encoding="utf-8") as f:
            for line in f:
                if line.startswith(f"{key} ="):
                    # overwrite the existing line
                    if isinstance(val, str):
                        lines.append(f"{key} = '{val}'\n")
                    else:
                        lines.append(f"{key} = {val}\n")
                    found = True
                else:
                    lines.append(line)
        if not found:
            # append at end
            if isinstance(val, str):
                lines.append(f"{key} = '{val}'\n")
            else:
                lines.append(f"{key} = {val}\n")
        with open(self.config_path, "w", encoding="utf-8") as f:
            f.writelines(lines)
    # End write_setting()


    # Helper to set-up/check initial configuration
    def config_app(self, settings: dict) -> None:
        """
        Sets up initial run configuration|checks exsisting configuration.
        """
        # Required and optional settings
        REQUIRED  = ("MODEL", "TEMP", "YOUR_NAME", "ASSISTANT_NAME", "OPENAI_API_KEY", "PROMPT_ID", "VECTOR_STORE_ID")
        DEFAULTS  = {"MODEL": "gpt-5.1", "TEMP": 0.3}

        # Prompt for missing required settings
        updated  = False
        for key in REQUIRED:
            if key not in settings or (key == "OPENAI_API_KEY" and not settings.get(key)):
                if key in DEFAULTS:
                    settings[key] = DEFAULTS[key]
                    print(f"No {key} found. Using default: {settings[key]}")
                else:
                    settings[key] = input(f"Enter {key}: ").strip()
                updated = True

        # Write settings file if needed
        if updated or not self.config_dir.exists():
            self.config_dir.mkdir(parents=True, exist_ok=True)
            with open(self.config_path, "w", encoding="utf-8") as f:
                f.write("# ~/.openai-assistant/settings.py  (auto-generated by openai-assistant)\n")
                for key in REQUIRED:
                    val = settings[key]
                    if isinstance(val, str):
                        f.write(f"{key} = '{val}'\n")
                    else:
                        f.write(f"{key} = {val}\n")
            print(f"Wrote settings to {self.config_path}")

        if not self.chats_dir.exists():
            self.chats_dir.mkdir(parents=True, exist_ok=True)

        if not self.images_dir.exists():
            self.images_dir.mkdir(parents=True, exist_ok=True)


    def cleanup_chat_files(self, min_size_bytes=50):
        """
        Delete all files in the chats dir smaller than min_size_b bytes.
        This will clean out "empty" chat files left over from unused
        sessions.
        """

        for filename in os.listdir(self.chats_dir):
            filepath = os.path.join(self.chats_dir, filename)
            if os.path.isfile(filepath):
                if os.path.getsize(filepath) < min_size_bytes:
                    os.remove(filepath)
# End class ConfigManager


def main():
    c = Console()

    # CLI flags
    parser = argparse.ArgumentParser(
        prog="openai-assistant",
        description="Terminal client for the OpenAI Requests API",
    )
    parser.add_argument(
        "--reset-prompt",
        action="store_true",
        help="Ignore and clear PROMPT_ID in settings before startup",
    )
    parser.add_argument(
        "--debug-api",
        action="store_true",
        help="Enable DEBUG level API logging to ~/.openai-assistant/api.log",
    )
    args = parser.parse_args()

    # Clear terminal
    os.system('clear')
    c.print(f"\n[#f5d676 b u]OpenAI Assistant {__version__}[/]\n")

    try:
        c.print("[green]Aquiring settings and configuration[/]")
        sleep(1)

        ## Some global definitions
        CONFIG_DIR  = Path.home() / ".openai-assistant"
        CONFIG_PATH = CONFIG_DIR / "settings.py"
        CHATS_DIR   = CONFIG_DIR / "chats/"
        IMAGES_DIR  = CONFIG_DIR / "images/"

        config_man = ConfigManager(CONFIG_DIR, CONFIG_PATH, CHATS_DIR, IMAGES_DIR)

        # Get and load settings, prompt for missing settings
        settings = config_man.load_settings()
        config_man.config_app(settings)

        # Apply resets if requested
        if args.reset_prompt:
            settings["PROMPT_ID"] = ""
            try:
                config_man.write_setting("PROMPT_ID", "")
                print("Reset PROMPT_ID in settings.")
            except Exception:
                pass

        # Configure API logger
        api_logfile = CONFIG_DIR / "api.log"
        api_logger = logging.getLogger("openai_assistant.api")
        api_logger.setLevel(logging.DEBUG if args.debug_api else logging.INFO)
        handler = TimedRotatingFileHandler(
            api_logfile,
            when="midnight",
            backupCount=7,
            encoding="utf-8",
        )
        handler.setFormatter(
            logging.Formatter("%(asctime)s %(levelname)s %(message)s")
        )
        if not any(
            getattr(h, "baseFilename", None) == handler.baseFilename
            for h in api_logger.handlers
        ):
            api_logger.addHandler(handler)
        api_logger.info("startup: settings initialised")

        c.print("[green]Connecting to OpenAI API endpoint[/]")
        sleep(1)

        # Launch the TUI
        app = OpenaiAssistant(
                settings, CONFIG_DIR, CHATS_DIR, IMAGES_DIR, api_logger
        )

        try:
            app.run()
        finally:
            try:
                if getattr(app, "lf", None):
                    app.lf.close()
            except Exception:
                pass
            try:
                config_man.cleanup_chat_files()
            except Exception:
                pass

    except Exception as e:
        c.print_exception(f"[red]Caught:[/] {e}")
# End main


if __name__ == "__main__":
    main()
