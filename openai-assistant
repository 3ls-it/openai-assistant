#!/usr/bin/env python3
"""
openai-assistant v3
Copyright 2025 J Adams jfa63[at]duck[dot]com
Released under the 2-Clause BSD license.
"""
__version__ = 'v3.0.4'
__author__ = 'J. Adams jfa63[at]duck[dot]com'

# Builtin imports
import argparse
import asyncio
import base64
from datetime import datetime
import logging
from logging.handlers import TimedRotatingFileHandler
import os
from pathlib import Path
import re
import runpy
import subprocess as proc
import sys
import textwrap
import threading
import time
from time import sleep
from typing import Any, Match

# PyLaTeX
from pylatexenc.latex2text import LatexNodes2Text

# OpenAI imports
import openai
from openai import OpenAI
from openai.types.vector_stores.vector_store_file_batch import VectorStoreFileBatch

# Rich imports for text output formatting
from rich.console import Console
from rich import print

# Textual imports
from textual import events, on
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import Container, Grid, VerticalScroll
from textual.message import Message
from textual.reactive import reactive, var
from textual.screen import ModalScreen, Screen
from textual.widgets import (Button,
                             DirectoryTree,
                             Footer,
                             Header,
                             Label,
                             Markdown,
                             Static,
                             TextArea,
                            )



## Global functions -------- #
# Convert LaTeX expressions to Unicode.
# Multiline \[ ... \] where \[ and \] are line-based (common).
# Allow mismatched indentation on closing delimiters.
# Also handle inline math \( ... \).
_LATEX2TEXT = LatexNodes2Text()

_DISPLAY_MATH_BLOCK = re.compile(
    r"^(?P<indent>[ \t]*)\\\[\s*\n(?P<body>.*?)\n[ \t]*\\\]\s*$",
    re.DOTALL | re.MULTILINE,
)

_INLINE_MATH_PARENS = re.compile(
    r"\\\(\s*(?P<body>.+?)\s*\\\)",
    re.DOTALL,
)

def _latex_to_pretty(latex: str) -> str:
    latex = textwrap.dedent(latex).strip()
    try:
        return _LATEX2TEXT.latex_to_text(latex).strip()
    except Exception:
        # fail-open: keep original latex
        return latex

def _fence(indent: str, text: str) -> str:
    lines = ["```", text, "```"]
    return "\n".join(indent + line for line in lines)

def _inline_code(s: str) -> str:
    if "`" not in s:
        return f"`{s}`"
    if "``" not in s:
        return f"``{s}``"
    return s

def normalize_math_for_markdown(text: str) -> str:
    def repl_display(m: Match[str]) -> str:
        indent = m.group("indent")
        pretty = _latex_to_pretty(m.group("body"))
        if not pretty.strip():
            return m.group(0)  # fail-open
        return _fence(indent, pretty)

    text = _DISPLAY_MATH_BLOCK.sub(repl_display, text)

    def repl_inline(m: Match[str]) -> str:
        pretty = _latex_to_pretty(m.group("body"))
        pretty = " ".join(pretty.splitlines()).strip()
        if not pretty:
            return m.group(0)  # fail-open
        return _inline_code(pretty)

    return _INLINE_MATH_PARENS.sub(repl_inline, text)
##



## Helper Classes -------- #
# Text input widget
class Input_TextArea(TextArea):
    """
    Encapsulates a TextArea widget for user input
    """
    def _on_submit(self) -> str:
        return self.text
# End Class Input_TextArea



# Widget for displaying user input
class DisplayPrompt(Markdown):
    """
    Encapsulates a Markdown widget for user input display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Prompt 



# Widget for displaying OpenAI responses 
class DisplayResponse(Markdown):
    """
    Encapsulates a Markdown widget for LLM response display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        text = normalize_math_for_markdown(text)
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Response



# Widget to display status messages
class StatusWidget(Static):
    BORDER_TITLE = "Status"
#



# Modal Screen with quit dialogue  
class QuitDialogue(ModalScreen):
    """
    Provides a ModalScreen with a quit dialogue box.
    Based on example code from the Textual website.
    """

    def compose(self) -> ComposeResult:
        yield Grid(
            Label("[#f5d676 b]Are you sure you want to quit?[/]", id="message"),
            Button("Quit", variant="warning", compact=True, id="quit"),
            Button("Cancel", variant="primary", compact=True, id="cancel"),
            id="quit_dialogue",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "quit":
            self.app.exit()
        else:
            self.app.pop_screen()
# End Class QuitDialogue



# Modal Screen with upload dialogue  
class UploadDialogue(ModalScreen):
    """
    Provides a ModalScreen with the upload confirmation dialogue box.
    Based on example code from the Textual website.
    """

    def __init__(self, fname):
        super().__init__()
        self.fname = os.path.basename(fname)

    def compose(self) -> ComposeResult:
        yield Grid(
            Label(f"[#f5d676 b]Upload {self.fname}?[/]", id="message"),
            Button("Upload", variant="success", compact=True, id="upload"),
            Button("Cancel", variant="primary", compact=True, id="cancel"),
            id="upload_dialogue",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "cancel":
            self.dismiss(False)
        elif event.button.id == "upload":
            self.dismiss(True)
# End Class UploadDialogue



# Modal Screen with upload result 
class UploadResult(ModalScreen):
    """
    Provides a ModalScreen with the upload progress/result.
    """

    def __init__(self, path, status):
        super().__init__()
        self.path = os.path.basename(path)
        self.status = status
        self.dismiss_button = Button(
                "Dismiss",
                variant="primary",
                compact=True,
                disabled=False,
                id="dismiss"
                )

    def compose(self) -> ComposeResult:
        if self.status == "cancelled":
            msg = f"[yellow]Upload of {self.path}[/] cancelled"
        elif self.status == "completed":
            msg = f"[green]Uploaded {self.path}[/]"
        elif self.status == "failed":
            msg = f"[red]Upload of {self.path} failed![/]"

        yield Grid(
            Label(msg, id="message"),
            self.dismiss_button,
            id="upload_result",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "dismiss":
            self.app.pop_screen()
# End Class UploadResult 



# Modal Screen with arbitrary message 
class AboutDialogue(ModalScreen):
    """
    Provides a ModalScreen with an info dialogue.
    Used for "About" when F1 is pressed.
    """

    def __init__(self, msg):
        super().__init__()
        self.msg = msg
        self.dismiss_button = Button(
                "Dismiss",
                variant="warning",
                compact=True,
                disabled=False,
                id="dismiss"
                )

    def compose(self) -> ComposeResult:
        yield Grid(
            Label(self.msg, id="message"),
            self.dismiss_button,
            id="info_dialogue",
        ) 

    def on_button_pressed(self, event: Button.Pressed) -> None:
        if event.button.id == "dismiss":
            self.app.pop_screen()
# End Class AboutDialogue 



class ChatFileSelected(Message):
    def __init__(self, sender, path, method):
        super().__init__()
        self.path = path
        self.method = method  # "left-click", "right-click" ^ "enter"
# End Class ChatFileSelected



class ChatDirectoryTree(DirectoryTree):
    async def on_directory_tree_file_selected(
                            self, event: DirectoryTree.FileSelected
    ) -> None:
        event.stop()

    async def on_mouse_down(self, event: events.MouseEvent) -> None:
        event.stop()
        node_index = event.style.meta.get("node")
        if node_index is not None:
            node = self.get_node_at_line(node_index)
            path = node.data.path  # full path
            if event.button == 1:  # Left click
                self.post_message(ChatFileSelected(self, path, "left-click"))
            elif event.button == 3:  # Right click
                self.post_message(ChatFileSelected(self, path, "right-click"))

    async def on_key(self, event: events.Key) -> None:
        if event.key == "enter":
            node = self.cursor_node
            if node is not None:
                path = node.data.path
                self.post_message(ChatFileSelected(self, path, "enter"))
# End Class ChatDirectoryTree



class ShowChat(Markdown):
    """
    Encapsulates a Markdown widget for chat file display
    """
    def __init__(self, text="", border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
# End Class ShowChat



class ChatBrowser(Screen):
    """
    Provides the screen for browsing/selecting previous
    chats.
    """
    def __init__(self, chats_dir, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.dir_path = chats_dir

    BINDINGS = [("escape", "app.pop_screen", "Close screen")]

    file_label = Label("[green b]Select File[/]", id="file-label")
    show_chat = ShowChat()


    def compose(self) -> ComposeResult:
        self.show_chat.visible = True

        yield Header()
        with Container():
            yield Label("")
            yield Label("[#f5d676 b]Chat Browser (ESC to quit)[/]")
            yield self.file_label
            yield Label("")
            yield self.show_chat
            yield ChatDirectoryTree(self.dir_path, id="chat-view")


    async def on_chat_file_selected(self, event: ChatFileSelected) -> None:
        """
        Called when the user clicks on a chat file.
        """
        event.stop()
        meth = event.method
        path = str(event.path)
        chat_fname = os.path.basename(path)
        
        if meth == "left-click":
            with open(path, "rt") as f:
               text = f.read() 
            self.file_label.update(f"[blue b]{chat_fname}[/]")
            # Convert LaTeX to Unicode
            content = normalize_math_for_markdown(text)
            self.show_chat.update(content) 
        elif meth == "enter":
            self.app.pop_screen()
            await self.app.continue_chat(path)
# End Class ChatBrowser



class ContinuationDialogue(ModalScreen):
    """
    Provides a ModalScreen for for chat continuation dialogue.
    Allows user to add instructions to the contiuation prompt.
    """

    def __init__(self):
        super().__init__()

        self.create_button = Button(
                "Continue",
                variant="primary",
                compact=True,
                disabled=False,
                id="continue")
        self.cancel_button = Button(
                "Cancel",
                variant="warning",
                compact=True,
                disabled=False,
                id="cancel")
        self.input_area = TextArea(
                placeholder="Further instructions...",
                id="instruction_input")


    def compose(self):
        yield Grid(
            Label("[#f5d676 b]Continue Conversation[/]", id="message"),
            Label("Additional Instructions (optional):", id="additional_instr"),
            self.input_area,
            self.create_button,
            self.cancel_button,
            id="continue_dialogue"
        )

    def on_mount(self):
        self.set_focus(self.input_area)

    def on_button_pressed(self, event):
        instr = self.input_area.text
        fut = getattr(self.app, "_instruction_future", None)
        if fut and not fut.done():
            if event.button.id == "continue":
                fut.set_result(instr)
            else:
                fut.set_result(None)
        self.app.pop_screen()
# End Class ContinuationDialogue 



class Openai_API():
    """
    Encapsulates an OpenAI client instance.
    """

    def __init__(self, config, logger=None):
        self.config = config
        self.api_key = self.config["OPENAI_API_KEY"]
        self.prompt_id = self.config["PROMPT_ID"]
        self.gpt_model = self.config["MODEL"]
        self.vector_store_id = self.config["VECTOR_STORE_ID"]
        self.client = OpenAI(api_key=self.api_key)
        self.logger = logger or logging.getLogger("openai_assistant.api")
        # server-side conversation object backing this chat session
        conv = self.client.conversations.create(
            metadata={
                "app": "openai-assistant",
            }
        )
        self.conversation_id = conv.id
        self.logger.info(f"Created conversation {self.conversation_id}")
        # lock to prevent concurrent operation on conversation
        self._conversation_lock = threading.Lock()
        self.vector_store = None
        ## Vector Store setup        
        if self.vector_store_id:
            self.vector_store = self.client.vector_stores.retrieve(
                 vector_store_id=self.vector_store_id
            )
            try:
                self.logger.info(f"vector_store retrieved id={self.vector_store.id}")
            except Exception as e:
                print(f"in Openai_API.__init__()\n{e}")


    def _ensure_conversation(self) -> None:
        """
        Create/ensure a Conversation object.
        """
        if self.conversation_id is not None:
            return

        conv = self.client.conversations.create(
            metadata={
                "app": "openai-assistant",
            }
        )
        self.conversation_id = conv.id
        self.logger.info(f"Created new conversation {self.conversation_id}")


    def get_conversation_id(self) -> str:
        """
        Return current Conversation ID.
        """
        return self.conversation_id


    def new_conversation(self) -> str:
        """
        Create new Conversation object on server, return
        new Conversation ID.
        """
        self.conversation_id = None
        self._ensure_conversation()
        return self.conversation_id


    def send_query(self, messages, lf=None,
                   images_dir=None, display_images=True
    ) -> tuple[str, list[str]]:
        """
        Sends a query to the OpenAI Responses API.
        - messages: str or list of message dicts (see OpenAI docs)
        - lf: open file handle for logging (optional but recommended)
        - images_dir: directory to save images (required for image output)
        - display_images: if True, try to display images with `feh`
        Returns: (text_response, list_of_image_paths)
        """

        if isinstance(messages, str):
            messages = [{"role": "user", "content": messages}]

        # Make sure we have a Conversation object
        self.logger.debug("in send_query(), calling _ensure_conversation()")
        self._ensure_conversation()

        start = time.time()

        # small retry loop for conversation_locked
        max_retries = 3
        backoff = 1.0  # seconds

        try:
            for attempt in range(1, max_retries + 1):
                try:
                    self.logger.debug("in send_query(),about to create responses object")
                    with self._conversation_lock:
                        resp = self.client.responses.create(
                            model=self.gpt_model,
                            input=messages,
                            prompt={
                                "id": self.prompt_id
                            },
                            conversation=self.conversation_id,
                            tools=[{"type": "image_generation", "partial_images": 0}],
                        )
                    self.logger.debug("in send_query(),response sent and returned")
                    break  # success, exit retry loop

                except openai.APIStatusError as e:
                    # Check specifically for conversation_locked
                    msg = str(e)
                    cond1 = "conversation_locked"
                    cond2 = "Another process is currently operating on this conversation"
                    if cond1 in msg or cond2 in msg:
                        try:
                            self.logger.warning(
                                "conversation_locked for conversation %s (attempt %d/%d); retrying in %.1fs",
                                self.conversation_id,
                                attempt,
                                max_retries,
                                backoff,
                            )
                        except Exception as er:
                            print(f"in send_query()\n{er}\n{e}")

                        if attempt == max_retries:
                            # Give up after max_retries; re-raise to fall through to your generic handler
                            raise
                        time.sleep(backoff)
                        continue
                    # Not a conversation_locked error: re-raise and let outer except handle it
                    raise
            # end retry loop

            text = resp.output_text or ""
            image_paths = []

            if images_dir:
                os.makedirs(images_dir, exist_ok=True)

            # Walk the structured outputs for images.
            for item in resp.output:
                if item.type == "image_generation_call":
                    image_base64 = item.result  # base64-encoded PNG/WebP/JPEG
                    now = datetime.now()
                    image_fname = f"image_{now:%Y%m%d_%H%M%S_%f}.png"
                    if images_dir is None:
                        raise ValueError("images_dir must be specified to save images.")
                    image_path = os.path.join(images_dir, image_fname)

                    try:
                        with open(image_path, "wb") as f:
                            f.write(base64.b64decode(image_base64))
                        image_paths.append(image_path)
                    except Exception as e:
                        self.logger.error(f"Saving {image_fname} failed: {e}")

            # Log image names to the chat log, if any
            if lf and image_paths:
                for img in image_paths:
                    lf.write(f"[image] {img}\n")
                lf.flush()

            # Display images, if any
            if display_images and image_paths:
                for img in image_paths:
                    try:
                        # Use 'feh' if present
                        proc.Popen(['feh', img])
                    except OSError:
                        # Try to fall back on ImageMagick
                        proc.Popen(['display', img])
                    except Exception as e:
                        self.logger.error(f"[system] Unable to display image: {e}")

            try:
                elapsed = time.time() - start
                self.logger.info(
                    f"run completed elapsed={elapsed:.2f}s resp_items={len(resp.output)}"
                )
            except Exception as e:
                print(f"in send_query()\n{e}")

            return text, image_paths

        # Log errros and notify
        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError: {e}")
            except Exception as er:
                print(f"in send_query()\n{er}\n{e}")
            return "The server could not be reached. Check log.", []

        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError: {e}")
            except Exception as er:
                print(f"in send_query()\n{er}\n{e}")
            return "A 429 status code was received; we should back off a bit.", []

        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError: {e}")
            except Exception as er:
                print(f"in send_query()\n{er}\n{e}")
            return 'A non-200-range status code was received. Check log.', []

        except Exception as e:
            try:
                self.logger.exception(f"Unexpected error during run: {e}")
            except Exception as er:
                print(f"in send_query()\n{er}\n{e}")
            return 'An unexpected error occurred while streaming. Check log.', []
    # End send_query()


    # Upload file to OpenAI account
    def file_upload(self, filename: str) -> VectorStoreFileBatch:
        """
        Uploads a file.
        """
        if not os.path.isfile(filename) or os.path.getsize(filename) == 0:
            try:
                self.logger.info(f"upload skipped: empty or missing file {filename}")
            except Exception as e:
                print(f"in file_upload()\n{e}")
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 1,
                                                     'completed': 0,
                                                     'failed': 0,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="cancelled")

        file_streams = []
        try:
            file_streams.append(open(filename, "rb"))
            try:
                self.logger.debug(f"uploading 1 file to vector_store_id={self.vector_store.id}")
            except Exception as e:
                print(f"in file_upload()\n{e}")
            file_batch = self.client.vector_stores.file_batches.upload_and_poll(
                vector_store_id=self.vector_store.id, files=file_streams
            )
            try:
                self.logger.info(f"upload status={file_batch.status} file_counts={file_batch.file_counts}")
            except Exception as e:
                print(f"in file_upload()\n{e}")
            return file_batch
        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError during upload: {e}")
            except Exception as e:
                print(f"in file_upload()\n{e}")
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError during upload: {e}")
            except Exception as er:
                print(f"in file_upload()\n{er}\n{e}")
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError during upload: {e}")
            except Exception as er:
                print(f"in file_upload()\n{er}\n{e}")
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except Exception as e:
            try:
                self.logger.error(f"Unexpected error during upload: {e}")
            except Exception as er:
                print(f"in file_upload()\n{er}\n{e}")
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        finally:
            for fs in file_streams:
                try:
                    fs.close()
                except Exception as e:
                    self.logger.debug(f"in file_upload()\n{e}")
    # End file_upload()
# End Class Openai_API 



class ConfigManager:
    """
    Encapsulates configuration management
    """
    def __init__(self, config_dir, config_path, chats_dir, images_dir):
        self.config_dir = config_dir
        self.config_path = config_path
        self.chats_dir = chats_dir
        self.images_dir = images_dir

    # Helper to load configuration settings
    def load_settings(self) -> dict:
        """
        Returns a configuration dictionary.
        """
        if self.config_path.is_file():
            return runpy.run_path(str(self.config_path))

        return {}
    # End load_settings()


    # Helper to update a single key in ~/.openai/settings.py
    def write_setting(self, key: str, val) -> None:
        """
        Writes a single key entry to settings file
        """
        lines = []
        found = False
        with open(self.config_path, "r", encoding="utf-8") as f:
            for line in f:
                if line.startswith(f"{key} ="):
                    # overwrite the existing line
                    if isinstance(val, str):
                        lines.append(f"{key} = '{val}'\n")
                    else:
                        lines.append(f"{key} = {val}\n")
                    found = True
                else:
                    lines.append(line)
        if not found:
            # append at end
            if isinstance(val, str):
                lines.append(f"{key} = '{val}'\n")
            else:
                lines.append(f"{key} = {val}\n")
        with open(self.config_path, "w", encoding="utf-8") as f:
            f.writelines(lines)
    # End write_setting()


    # Helper to set-up/check initial configuration
    def config_app(self, settings: dict[str, Any]) -> bool:
        """
        Sets up initial run configuration and checks existing configuration.
        Prompts interactively for missing values.
        """

        REQUIRED = (
            "MODEL",
            "YOUR_NAME",
            "ASSISTANT_NAME",
            "OPENAI_API_KEY",
            "PROMPT_ID",
            "VECTOR_STORE_ID",
        )

        DEFAULTS = {
            "MODEL": "gpt-5.2",
            "YOUR_NAME": "User",
            "ASSISTANT_NAME": "Assistant",
        }

        # Nice labels for prompts
        LABELS = {
            "MODEL": "model",
            "YOUR_NAME": "your name",
            "ASSISTANT_NAME": "assistant name",
            "OPENAI_API_KEY": "OpenAI API key",
            "PROMPT_ID": "Prompt ID",
            "VECTOR_STORE_ID": "Vector Store ID",
        }

        first_run = not self.config_path.exists()
        updated = False
        incomplete = False
        missing_ids: list[str] = []

        # 1. MODEL / YOUR_NAME / ASSISTANT_NAME:
        #    prompt with default, allow Enter to accept default.
        for key in ("MODEL", "YOUR_NAME", "ASSISTANT_NAME"):
            current = (settings.get(key) or "").strip()
            if not current:
                default = DEFAULTS[key]
                label = LABELS.get(key, key)
                resp = input(f"Enter {label} [{default}]: ").strip()
                settings[key] = resp or default
                print(f"Using {key} = {settings[key]!r}")
                updated = True

        # 2. IDs & API key: require a value, but allow blank with warning.
        for key in ("OPENAI_API_KEY", "PROMPT_ID", "VECTOR_STORE_ID"):
            current = (settings.get(key) or "").strip()
            if not current:
                label = LABELS.get(key, key)
                resp = input(f"Enter {label} (leave blank to skip for now): ").strip()
                settings[key] = resp  # may be empty string
                updated = True
                if not resp:
                    incomplete = True
                    missing_ids.append(key)

        # 3. Write settings file if needed
        if updated or first_run:
            self.config_dir.mkdir(parents=True, exist_ok=True)
            with open(self.config_path, "w", encoding="utf-8") as f:
                f.write(
                    "# ~/.openai-assistant/settings.py  "
                    "(auto-generated by openai-assistant)\n"
                )
                for key in REQUIRED:
                    val = settings.get(key, "")
                    if isinstance(val, str):
                        f.write(f"{key} = '{val}'\n")
                    else:
                        f.write(f"{key} = {val}\n")
            print(f"Wrote settings to [cyan]{self.config_path}[/]")

        # 4. Warn about incomplete configuration if any IDs are missing
        if incomplete:
            missing_str = ", ".join(missing_ids)
            print(
                "\n[red b][WARNING][/] Configuration is incomplete.\n"
                f"Missing/empty: [#f5d676]{missing_str}[/]\n\n"
                f"You can re-run the setup by running the program again,\n"
                f"or edit [cyan]{self.config_path}[/] manually.\n"
            )
            return False

        # 5. Ensure data directories exist
        if not self.chats_dir.exists():
            self.chats_dir.mkdir(parents=True, exist_ok=True)
        if not self.images_dir.exists():
            self.images_dir.mkdir(parents=True, exist_ok=True)

        return True
    # End config_app()


    def cleanup_chat_files(self, min_size_bytes=50):
        """
        Delete all files in the chats dir smaller than min_size_b bytes.
        This will clean out "empty" chat files left over from unused
        sessions.
        """

        for filename in os.listdir(self.chats_dir):
            filepath = os.path.join(self.chats_dir, filename)
            if os.path.isfile(filepath):
                if os.path.getsize(filepath) < min_size_bytes:
                    os.remove(filepath)
# End class ConfigManager



# App Class -------- #
class OpenaiAssistant(App):
    """
    Openai-Assistant application class.
    """

    def __init__(self, config, config_dir, chats_dir,
                 images_dir, api_logger, *args, **kwargs
    ):
        super().__init__(*args, **kwargs)
        self.config = config
        self.config_dir = config_dir
        self.chats_dir = chats_dir
        self.images_dir = images_dir

        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.user_name = self.config["YOUR_NAME"]

        # Create API instance
        self.api_logger = api_logger
        self.api = Openai_API(self.config, logger=self.api_logger)

        try:
            self.api_logger.info("config: model="+str(self.config.get('MODEL'))+ \
                " temp="+str(self.config.get('TEMP'))+ \
                " prompt_id="+("yes" if self.config.get('PROMPT_ID') else "no")+ \
                " vector_store_id="+("yes" if self.config.get('VECTOR_STORE_ID') else "no")
            )
        except Exception as e:
            print(f"{e}") # will print in Textual dev console

        # Chat log setup
        now = datetime.now()
        # Format as e.g. '9 June 2025 9:52pm'
        self.tstamp = now.strftime('%-d %B %Y %-I:%M%p')
        # No spaces in filename
        stamp = self.tstamp.replace(" ", "_")
        self.logfile = self.chats_dir / f"{stamp}-chat_log.txt"

        # Open chat log file in append mode
        self.lf = open(self.logfile, 'a', encoding='utf-8')
        # Write timestamp to log file for session date
        self.lf.write(f"\nSession time stamp: {self.tstamp}\n")
        self.lf.flush()
    # End constructor


    TITLE = "OpenAI Assistant"
    SUB_TITLE = f"{__version__}  •  Submit: Ctrl+\\  •  Quit: Ctrl+Q"
    AUTO_FOCUS = "Input_TextArea"

    # Key bindings for Footer and help panel 
    BINDINGS = [
        Binding(key="ctrl+backslash", action="submit", description="Submit Input"),
        Binding(key="ctrl+q", action="quit", description="Quit"),
        Binding(key="ctrl+b", action="toggle_file_view", description="Toggle File-Upload Browser"),
        Binding(key="f1", action="about", description="About"),
        Binding("f2", "push_screen('chat_browser')", "Browse/Continue Chats"),
        Binding(key="f3", action="new_chat", description="New Chat"),
    ]

    #Hide file tree on start 
    show_tree = var(False)
    path: reactive[str | None] = reactive(None)

    # Style sheets for widgets 
    CSS = """
    DisplayPrompt {
        border: round cyan;
        background: $primary 10%;
        color: $text;
        margin: 1;        
        margin-right: 4;
        padding: 1 2 0 2;
    }

    DisplayResponse {
        border: round #f5d676;
        background: gray 10%;   
        color: $text;             
        margin: 1;      
        margin-left: 4; 
        padding: 1 2 0 2;
    }

    Input_TextArea {
        border: round blue;
        height: 20%;
    }

    ShowChat {
        border: round #f5d676;
        height: 90%;
        overflow: auto;
    }

    StatusWidget {
        border: round #f5d676;
    }

    #tree-view {
        display: none;
        scrollbar-gutter: stable;
        overflow: auto;
        width: auto;
        height: 100%;
        dock: left;
    }

    #chat-view {
        scrollbar-gutter: stable;
        overflow: auto;
        width: auto;
        height: 100%;
        dock: left;
    }

    OpenaiAssistant.-show-tree #tree-view {
        display: block;
        max-width: 50%;
    }

    ChatBrowser.-show-tree #chat-view {
        display: block;
        max-width: 25%;
    }

    ChatBrowser {
        align: center middle;
    }

    QuitDialogue {
        align: center middle;
    }

    UploadDialogue {
        align: center middle;
    }

    UploadResult {
        align: center middle;
    }

    ContinuationDialogue {
        align: center middle;
    }

    AboutDialogue {
        align: center middle;
    }

    #quit_dialogue {
        grid-size: 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 40;
        height: 11;
        border: thick $background 80%;
        background: $surface;
    }

    #upload_dialogue {
        grid-size: 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 50;
        height: 10;
        border: thick $background 80%;
        background: $surface;
    }

    #upload_result {
        grid-size: 1 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 3;
        padding: 0 1;
        width: 50;
        height: 10;
        border: thick $background 80%;
        background: $surface;
    }

    #info_dialogue {
        grid-size: 1 2;
        grid-gutter: 1 2;
        grid-rows: 1fr 5;
        padding: 0 1;
        width: 50;
        height: 20;
        border: thick $background 80%;
        background: $surface;
    }

    #continue_dialogue {
        grid-size: 2 4;
        grid-gutter: 1;
        grid-rows: 1fr 1fr 8fr 1fr;
        padding: 0 1;
        width: 60;
        height: 28;
        border: thick $background 80%;
        background: $surface;
    }


    #instruction_input {
        column-span: 2;
        height: 15;
    }

    #additional_instr {
        column-span: 2;
    }

    #message {
        column-span: 2;
        height: 1fr;
        width: 1fr;
        content-align: center middle;
    }

    #status {
        dock: bottom;
        background: $panel;
        color: $text;
        padding: 0;
    }

    Button {
        width: 100%;
    }
    """


    # Methods -------- #
    def on_mount(self) -> None:
        """
        Sets default theme and installs the chat browser screen.
        """
        self.theme = "flexoki"
        self.install_screen(ChatBrowser(self.chats_dir), name='chat_browser')
        self.show_status(f"Chat timestamp {self.tstamp}")


    def compose(self) -> ComposeResult:
        """
        Composes UI elements.
        """
        self.input_area = Input_TextArea(id="input_area")
        self.chat_view = VerticalScroll(id="chat_view")

        path = Path.home()
        resp_area = DisplayResponse(
            f"Hello {self.user_name}! Just type your input below to start a chat.\n\n"
             "`Ctrl+Backslash` Submit input\n\n"
             "`Enter` New line\n\n"
             "`Ctrl+Q` Quit\n\n"
             "`Tab` Toggle widget focus\n\n"
             "`F2` Continue a chat\n\n"
             "`F3` Start new chat",
            border_title="New Chat",
        )
        yield Header(show_clock=True)
        with Container():
            with self.chat_view:
                yield resp_area
            yield self.input_area
            yield StatusWidget("", id="status")
            yield DirectoryTree(path, id="tree-view")
        yield Footer()


    @on(events.Key)
    async def on_key(self, event: events.Key) -> None:
        """
        The keystroke ctrl+backslash submits user input to the API,
        then displays returned result.
        """
        if event.key == "ctrl+backslash":
            self.show_status("")
            text = self.input_area._on_submit()
            if not text:
                return
            try:
                if self.lf:
                    self.lf.write("\n[user] "+text+"\n\n")
            except Exception as e:
                self.notify(f"[red]Error writing user input to log: {e}",
                            title="Write Error!",
                            severity="error",
                            timeout=5)

            self.input_area.load_text("Thinking...")
            self.show_status("Sending query")
            await self.chat_view.mount(
                DisplayPrompt(text, border_title=self.user_name))

            start = time.time()
            self.api.logger.debug(f"calling send_query() at {start}")
            resp, image_path = await asyncio.to_thread(
                    self.api.send_query, text, self.lf, self.images_dir)
            elapsed = time.time() - start

            has_text = bool(resp and resp.strip())
            if has_text:
                try:
                    if self.lf:
                        self.lf.write("\n[assistant] " + resp + "\n\n")
                        self.lf.flush()
                except Exception as e:
                    self.notify(
                        f"[red]Error writing AI response to log: {e}",
                        title="Error Saving File!",
                        severity="error",
                        timeout=5,
                    )

                await self.chat_view.mount(
                    DisplayResponse(resp, border_title=self.assistant_name)
                )

            self.input_area.clear()
            self.show_status(f"Run completed in {elapsed:.2f}s")
    # End on_key() 


    def on_directory_tree_file_selected(
        self, event: DirectoryTree.FileSelected
    ) -> None:
        """
        Called when the user clicks a file in the directory tree.
        """
        event.stop()
        self.path = str(event.path)

        # Called when UploadDialogue is dismissed.
        def _check_upload(upload: bool | None) -> None:
            if upload:
                self.do_file_upload(self.path)
        # End

        upload_dialogue = UploadDialogue(self.path)
        self.push_screen(upload_dialogue, _check_upload)


    def watch_show_tree(self, show_tree: bool) -> None:
        """
        Called when show_tree is modified.
        """
        self.set_class(show_tree, "-show-tree")


    # Status widget helper method
    def show_status(self, message: str) -> None:
        """
        Updates status window.
        """
        status = self.query_one("#status", StatusWidget)
        status.update(message)


    def do_file_upload(self, path: str) -> None:
        """
        Uploads file to Vector Store
        """
        result = self.api.file_upload(path)
        status = result.status.strip()
        uploaded = UploadResult(path, status)
        self.push_screen(uploaded)


    async def continue_chat(self, chpath: str) -> None:
        """
        Run the ContinuationDialogue and get further instructions
        if any. Call actual continuation
        """

        ## calback function
        def _on_done(fut: asyncio.Future):
            try:
                further = fut.result()
            except Exception as e:
                self.api.logger.debug(f"in continue_chat()._on_done()\n{e}")

            if further is not None:
                asyncio.create_task(self._run_continue(chpath, further))
        ##

        loop = asyncio.get_running_loop()
        self._instruction_future = loop.create_future()
        self.push_screen(ContinuationDialogue())
        self._instruction_future.add_done_callback(_on_done)
    # End continue_chat()


    async def _run_continue(self, chpath: str, further: str) -> None: 
        """
        Here we construct a continuation prompt, re-open the chat file
        and send the continuation prompt to the API.
        """

        # Continuation instructions
        inst = """
        Here is a previous chat log. Please summarize the key points
        and continue the conversation from where it left off.
        """

        chname = os.path.basename(chpath)
        self.input_area.load_text("Thinking...")
        self.show_status(f"Loading chat: {chname}")
         
        # Read chat file
        with open(chpath, 'r', encoding="utf-8") as f:
            chat_history = f.read()

        # Concat instructions, chat log and further instructions
        prompt = f"{inst}\n\nChat log:\n{chat_history}"
        if further.strip():
            prompt += f"\n\nFurther instructions:\n{further}"

        # Close existing log file
        self.lf.flush()
        self.lf.close()
        # Re-open selected chat
        now = datetime.now()
        tstamp = now.strftime('%-d %B %Y %-I:%M%p')
        self.lf = open(chpath, "a", encoding="utf-8")
        self.lf.write(f"\nContinuing session at: {tstamp}\n\n")
        self.lf.write(f"[further instructions] {further}\n\n")
        self.lf.flush()

        # Send prompt and await response
        start = time.time()
        resp, _ = await asyncio.to_thread(
                self.api.send_query, prompt, self.lf, self.images_dir)
        elapsed = time.time() - start

        has_text = bool(resp and resp.strip())
        if has_text:
            try:
                if self.lf:
                    self.lf.write("\n[assistant] " + resp + "\n\n")
                    self.lf.flush()
            except Exception as e:
                self.notify(
                    f"[red]Error writing AI response to log: {e}",
                    title="Error Saving File!",
                    severity="error",
                    timeout=5,
                )

            # Clear main chat window
            await self.chat_view.remove_children()
            await self.chat_view.mount(
                DisplayResponse(resp, border_title=self.assistant_name)
            )

        # Clear input box
        self.input_area.clear()
        self.show_status(f"Run completed in {elapsed:.2f}s")
    # End _run_continue()


    async def action_new_chat(self) -> None:
        """
        Creates a new chat
        """
        # Close existing log file
        if self.lf:
            self.lf.flush()
            self.lf.close()

        # Reset Conversation object
        self.api.new_conversation()
        # Open new chat log
        now = datetime.now()
        tstamp = now.strftime('%-d %B %Y %-I:%M%p')
        stamp = tstamp.replace(" ", "_")
        self.logfile = self.chats_dir / f"{stamp}-chat_log.txt"

        try:
            if self.lf:
                # Open chat log file in append mode
                self.lf = open(self.logfile, 'a', encoding='utf-8')
                # Write timestamp to log file for session date
                self.lf.write(f"\nSession time stamp: {tstamp}\n")
                self.lf.flush()
        except Exception as e:
            self.notify(
                f"[red]Error writing to chat log: {e}",
                title="Error Saving File!",
                severity="error",
                timeout=5,
            )

        await self.chat_view.remove_children()
        await self.chat_view.mount(
            DisplayResponse(f"New chat {tstamp}", border_title="New Chat")
        )
        self.show_status(f"Chat timestamp {tstamp}")


    def action_toggle_file_view(self) -> None:
        """
        Called in response to key binding.
        """
        self.query_one("#tree-view", DirectoryTree).reload()
        self.show_tree = not self.show_tree


    def action_quit(self) -> None:
        """
        Action to display the quit dialogue.
        """
        self.push_screen(QuitDialogue())


    def action_about(self) -> None:
        """
        Action to display the info dialogue.
        """
        msg = f"""
        [#f5d676 b]OpenAI Assistant {__version__}[/]\n\n
Released under the Two-Clause BSD License\n
   (c) 2025 J. Adams jfa63atduckdotcom
        """
        self.push_screen(AboutDialogue(msg))
# End Class OpenaiAssistant



def main():
    c = Console()

    # CLI flags
    parser = argparse.ArgumentParser(
        prog="openai-assistant",
        description="Terminal client for the OpenAI Requests API",
    )
    parser.add_argument(
        "--reset-prompt",
        action="store_true",
        help="Ignore and clear PROMPT_ID in settings before startup",
    )
    parser.add_argument(
        "--debug-api",
        action="store_true",
        help="Enable DEBUG level API logging to ~/.openai-assistant/api.log",
    )
    args = parser.parse_args()

    # Clear terminal
    os.system('clear')
    c.print(f"\n[#f5d676 b u]OpenAI Assistant {__version__}[/]\n")

    try:
        c.print("[green]Aquiring settings and configuration[/]")
        sleep(1)

        ## Some global definitions
        CONFIG_DIR  = Path.home() / ".openai-assistant"
        CONFIG_PATH = CONFIG_DIR / "settings.py"
        CHATS_DIR   = CONFIG_DIR / "chats/"
        IMAGES_DIR  = CONFIG_DIR / "images/"

        config_man = ConfigManager(CONFIG_DIR, CONFIG_PATH, CHATS_DIR, IMAGES_DIR)

        # Get and load settings, prompt for missing settings
        settings = config_man.load_settings()
        is_config = config_man.config_app(settings)
        if not is_config:
            sys.exit()

        # Apply resets if requested
        if args.reset_prompt:
            settings["PROMPT_ID"] = ""
            try:
                config_man.write_setting("PROMPT_ID", "")
                print("Reset PROMPT_ID in settings.")
            except Exception as e:
                c.print_exception(f"[red]Caught:[/] {e}")

        # Configure API logger
        api_logfile = CONFIG_DIR / "api.log"
        api_logger = logging.getLogger("openai_assistant.api")
        api_logger.setLevel(logging.DEBUG if args.debug_api else logging.INFO)
        handler = TimedRotatingFileHandler(
            api_logfile,
            when="midnight",
            backupCount=7,
            encoding="utf-8",
        )
        handler.setFormatter(
            logging.Formatter("%(asctime)s %(levelname)s %(message)s")
        )
        if not any(
            getattr(h, "baseFilename", None) == handler.baseFilename
            for h in api_logger.handlers
        ):
            api_logger.addHandler(handler)
        api_logger.info("startup: settings initialised")

        c.print("[green]Connecting to OpenAI API endpoint[/]")
        sleep(1)

        # Launch the TUI
        app = OpenaiAssistant(
                settings, CONFIG_DIR, CHATS_DIR, IMAGES_DIR, api_logger
        )

        try:
            app.run()
        finally:
            try:
                if getattr(app, "lf", None):
                    app.lf.close()
            except Exception as e:
                api_logger.debug(f"in main()\n{e}")
            try:
                config_man.cleanup_chat_files()
            except Exception as e:
                api_logger.debug(f"in main()\n{e}")

    except Exception as e:
        c.print_exception(f"[red]Caught:[/] {e}")
# End main


if __name__ == "__main__":
    main()
