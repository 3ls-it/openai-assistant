#!/usr/bin/env python3
"""
openai-assistant v2
Copyright 2025 J Adams jfa63[at]duck[dot]com
Released under the 2-Clause BSD license.
"""
__version__ = 'v2.1.0'
__author__ = 'J. Adams jfa63[at]duck[dot]com'

# Builtin imports
import argparse
import asyncio
from datetime import datetime
import os
from pathlib import Path
import runpy
from time import sleep
import warnings
import logging
from logging.handlers import TimedRotatingFileHandler
import time

# OpenAI imports
import openai
from openai import OpenAI
from openai import AssistantEventHandler
from openai.types.vector_stores.vector_store_file_batch import VectorStoreFileBatch

# Importing overide for EventHandler
from typing_extensions import override

# Rich imports for text output formatting
from rich import print

# Textual imports
from textual import events, on
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import VerticalScroll
from textual.widgets import Header, Footer, Markdown, TextArea




## Top-level functions -------- #
# Helper to load configuration settings
def load_settings() -> dict:
    """
    Returns a configuration dictionary.
    """
    if CONFIG_PATH.is_file():
        return runpy.run_path(str(CONFIG_PATH))
    return {}
# End load_settings()


# Helper to update a single key in ~/.openai/settings.py
def write_setting(key: str, val) -> None:
    """
    Writes a single key entry to settings file
    """
    lines = []
    found = False
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        for line in f:
            if line.startswith(f"{key} ="):
                # overwrite the existing line
                if isinstance(val, str):
                    lines.append(f"{key} = '{val}'\n")
                else:
                    lines.append(f"{key} = {val}\n")
                found = True
            else:
                lines.append(line)
    if not found:
        # append at end
        if isinstance(val, str):
            lines.append(f"{key} = '{val}'\n")
        else:
            lines.append(f"{key} = {val}\n")
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        f.writelines(lines)
# End write_setting()


# Helper to set-up/check initial configuration
def config_app() -> None:
    """
    Sets up initial run configuration|checks exsisting configuration.
    """
    # Required and optional settings
    REQUIRED  = ("MODEL", "TEMP", "YOUR_NAME", "ASSISTANT_NAME", "OPENAI_API_KEY")
    DEFAULTS  = {"MODEL": "gpt-4.1", "TEMP": 0.3, "YOUR_NAME": "User", "ASSISTANT_NAME": "OpenAI"}
    OPTIONAL  = ("FURTHER_INSTRUCTIONS", "VECTOR_STORE_ID", "ASSISTANT_ID")

    # Prompt for missing required settings
    updated  = False
    for key in REQUIRED:
        if key not in settings or (key == "OPENAI_API_KEY" and not settings.get(key)):
            if key in DEFAULTS:
                settings[key] = DEFAULTS[key]
                print(f"No {key} found. Using default: {settings[key]}")
            else:
                settings[key] = input(f"Enter {key}: ").strip()
            updated = True

    # Ensure optional settings exist
    for key in OPTIONAL:
        if key not in settings:
            settings[key] = ""
            updated = True

    # Write settings file if needed
    if updated or not CONFIG_PATH.exists():
        CONFIG_DIR.mkdir(parents=True, exist_ok=True)
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            f.write("# ~/.openai/settings.py  (auto-generated by openai-assistant)\n")
            for key in REQUIRED + OPTIONAL:
                val = settings[key]
                if isinstance(val, str):
                    f.write(f"{key} = '{val}'\n")
                else:
                    f.write(f"{key} = {val}\n")
        print(f"Wrote settings to {CONFIG_PATH}")
# End config_app() 



## Helper Classes -------- #
# Text input widget
class Input_TextArea(TextArea):
    """
    Encapsulates a TextArea widget for user input
    """
    def _on_submit(self) -> str:
        return self.text
# End Class Input_TextArea


# Widget for displaying user input
class DisplayPrompt(Markdown):
    """
    Encapsulates a Markdown widget for user input display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Prompt 


# Widget for displaying OpenAI responses 
class DisplayResponse(Markdown):
    """
    Encapsulates a Markdown widget for LLM response display
    """
    def __init__(self, text, border_title="", *args, **kwargs):
        super().__init__(text, *args, **kwargs)
        self.border_title = border_title
# End Class Response


# Extend the EventHandler class 
class EventHandler(AssistantEventHandler):
    """
    Extend the EventHandler class overriding two methods
    to handle the events in the response stream.
    Added text attribute to collect text deltas
    """
    def __init__(self):
        # Initialize handler to set up internal state
        super().__init__()
        # Accumulate streamed text 
        self.text = ''

    #@override
    #def on_text_created(self, text) -> None:
    #    pass

    @override
    def on_text_delta(self, delta, snapshot):
        resp = str(delta.value)
        # Concatenate deltas for display.
        self.text += resp

    def on_tool_call_created(self, tool_call):
        try:
            if lf:
                lf.write(f'\n> {tool_call.type}\n')
        except Exception as e:
            print(f"[red]Log write error in on_tool_call_created():[/] {e}")
        
    # For now we just write the input, output and logs to
    # ~/.openai/chat_log.txt
    def on_tool_call_delta(self, delta, snapshot):
        try:
            if delta.type == 'code_interpreter':
                if delta.code_interpreter.input and lf:
                    lf.write(delta.code_interpreter.input)
                if delta.code_interpreter.outputs and lf:
                    lf.write('\n\nOutput >')
                    for output in delta.code_interpreter.outputs:
                        if output.type == 'logs':
                            lf.write(f'\n{output.logs}')
        except Exception as e:
            print(f"[red]Log write error in on_tool_call_delta():[/] {e}")
# End Class EventHandler


class Openai_API():
    """
    Encapsulates an OpenAI client instance.
    """
    # Turn off DepricationWarnings
    # We know Assistans API is to be depricated in 2026 
    warnings.filterwarnings("ignore", category=DeprecationWarning)

    def __init__(self, config, logger=None):
        self.config = config
        self.api_key = self.config["OPENAI_API_KEY"]
        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.your_name = self.config["YOUR_NAME"]
        self.gpt_model = self.config["MODEL"]
        self.temp = self.config["TEMP"]
        self.client = OpenAI(api_key=self.api_key)
        self.assistant = None
        self.logger = logger or logging.getLogger("openai_assistant.api")
        self.vector_store = None
        self.thread = None


    # Upload file to OpenAI account
    def file_upload(self, filename: str) -> VectorStoreFileBatch:
        """
        Uploads a file.
        """
        if not os.path.isfile(filename) or os.path.getsize(filename) == 0:
            try:
                self.logger.info(f"upload skipped: empty or missing file {filename}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 1,
                                                     'completed': 0,
                                                     'failed': 0,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="cancelled")

        file_streams = []
        try:
            file_streams.append(open(filename, "rb"))
            try:
                self.logger.debug(f"uploading 1 file to vector_store_id={self.vector_store.id}")
            except Exception:
                pass
            file_batch = self.client.vector_stores.file_batches.upload_and_poll(
                vector_store_id=self.vector_store.id, files=file_streams
            )
            try:
                self.logger.info(f"upload status={file_batch.status} file_counts={file_batch.file_counts}")
            except Exception:
                pass
            return file_batch
        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        except Exception as e:
            try:
                self.logger.error(f"Unexpected error during upload: {e}")
            except Exception:
                pass
            return VectorStoreFileBatch(id="",
                                        created_at=0,
                                        file_counts={'cancelled': 0,
                                                     'completed': 0,
                                                     'failed': 1,
                                                     'in_progress': 0,
                                                     'total': 0},
                                        object="vector_store.files_batch",
                                        vector_store_id="",
                                        status="failed")
        finally:
            for fs in file_streams:
                try:
                    fs.close()
                except Exception:
                    pass
    # End file_upload()


    def setup(self, upload_log: bool = True) -> VectorStoreFileBatch:
        """
        Creates Assistant instance and Vector Store.
        """
        ## Assistant setup
        # Compose baseline instructions and append any user-provided
        # additional guidance from settings (FURTHER_INSTRUCTIONS).
        instructions = f"You are {self.assistant_name}, {self.your_name}'s personal AI assistant."
        further = (self.config.get("FURTHER_INSTRUCTIONS") or "").strip()
        if further:
            instructions = f"{instructions}\n\n{further}"

        if self.config.get("ASSISTANT_ID"):
         self.assistant = self.client.beta.assistants.retrieve(
             assistant_id=self.config["ASSISTANT_ID"]
         )
         try:
             self.logger.info(f"assistant retrieved id={self.assistant.id} model={self.gpt_model}")
         except Exception:
             pass
        else:
         # Prompt for assistant creation
         print("No ASSISTANT_ID found. Creating new assistant...")
         self.assistant = self.client.beta.assistants.create(
             instructions=instructions,
             name=self.assistant_name,
             tools=[{"type": "code_interpreter"}, {"type": "file_search"}],
             model=self.gpt_model,
             temperature=self.temp
         )
         print(f"Created new assistant with ID {self.assistant.id}")
         try:
             self.logger.info(f"assistant created id={self.assistant.id} model={self.gpt_model}")
         except Exception:
             pass
         resp = input("Save ASSISTANT_ID to config? [Y/n] ").strip().lower()
         if resp in ("", "y", "yes"):
             write_setting("ASSISTANT_ID", self.assistant.id)
             print("Updated ASSISTANT_ID in config.")
         else:
             print("ASSISTANT_ID not saved; will create new next run.")

        ## Vector Store setup
        if self.config.get("VECTOR_STORE_ID"):
         self.vector_store = self.client.vector_stores.retrieve(
             vector_store_id=self.config["VECTOR_STORE_ID"]
         )
         try:
             self.logger.info(f"vector_store retrieved id={self.vector_store.id}")
         except Exception:
             pass
        else:
         print("No VECTOR_STORE_ID found. Creating new vector store...")
         self.vector_store = self.client.vector_stores.create(name="Chat History")
         print(f"Created new vector store with ID {self.vector_store.id}")
         try:
             self.logger.info(f"vector_store created id={self.vector_store.id}")
         except Exception:
             pass
         resp = input("Save VECTOR_STORE_ID to config? [Y/n] ").strip().lower()
         if resp in ("", "y", "yes"):
             write_setting("VECTOR_STORE_ID", self.vector_store.id)
             print("Updated VECTOR_STORE_ID in config.")
         else:
             print("VECTOR_STORE_ID not saved; will create new next run.")

        ## Upload chat_log.txt (optional)
        if upload_log:
            upload = self.file_upload(logfile)
        else:
            upload = VectorStoreFileBatch(
                id="",
                created_at=0,
                file_counts={
                    "cancelled": 1,
                    "completed": 0,
                    "failed": 0,
                    "in_progress": 0,
                    "total": 0,
                },
                object="vector_store.files_batch",
                vector_store_id=self.vector_store.id if self.vector_store else "",
                status="cancelled",
            )

        ## Update assistant with vector store and ensure instructions are in-sync
        update_kwargs = {
            "assistant_id": self.assistant.id,
            "tool_resources": {"file_search": {"vector_store_ids": [self.vector_store.id]}},
        }
        updated_instructions = False
        try:
            if (self.assistant.instructions or "") != instructions:
                update_kwargs["instructions"] = instructions
                updated_instructions = True
        except Exception:
            update_kwargs["instructions"] = instructions
            updated_instructions = True

        try:
            self.assistant = self.client.beta.assistants.update(**update_kwargs)
        except Exception as e:
            try:
                self.logger.warning(f"failed to update assistant resources/instructions: {e}")
            except Exception:
                pass
            try:
                if lf:
                    lf.write(str(e))
            except Exception:
                pass
            print("[red]Warning:[/] Failed to update assistant tool resources/instructions; proceeding without vector store update.")
        else:
            if updated_instructions:
                print("Synced assistant instructions with settings: [#f5d676]YOUR_NAME[/] and [#f5d676]FURTHER_INSTRUCTIONS[/].")
                try:
                    self.logger.info("assistant instructions synced with settings")
                except Exception:
                    pass

        ## Create thread
        self.thread = self.client.beta.threads.create()
        try:
            self.logger.info(f"thread created id={self.thread.id}")
        except Exception:
            pass
        return upload
    # End setup() 


    def send_query(self, query: str) -> str:
        """
        Creates a query message, submits to the API, streams response
        then returns resp as a string.
        """
        resp = ''
        try:
            ## Create a message from the user query.
            self.client.beta.threads.messages.create(
                thread_id=self.thread.id,
                role="user",
                content=query
            )

            ## Then, we use the `stream` SDK helper
            # with the `EventHandler` class to create the Run
            # and stream the response.
            try:
                self.logger.info("run started")
                start = time.time()
            except Exception:
                pass
            with self.client.beta.threads.runs.stream(
                thread_id=self.thread.id,
                assistant_id=self.assistant.id,
                event_handler=EventHandler(),
            ) as stream:
                stream.until_done()
                resp = stream.text
            try:
                elapsed = time.time() - start
                self.logger.info(f"run completed elapsed={elapsed:.2f}s resp_len={len(resp)}")
            except Exception:
                pass

        except openai.APIConnectionError as e:
            try:
                self.logger.error(f"APIConnectionError: {e}")
            except Exception:
                pass
            return "The server could not be reached. Check log."

        except openai.RateLimitError as e:
            try:
                self.logger.error(f"RateLimitError: {e}")
            except Exception:
                pass
            return "A 429 status code was received; we should back off a bit."

        except openai.APIStatusError as e:
            try:
                self.logger.error(f"APIStatusError: {e}")
            except Exception:
                pass
            return 'A non-200-range status code was received. Check log.'
        except Exception as e:
            try:
                self.logger.error(f"Unexpected error during run: {e}")
            except Exception:
                pass
            return 'An unexpected error occurred while streaming. Check log.'
        return resp
    # End send_query() 
# End Class Openai_API 


# App Class -------- #
class OpenaiAssistant(App):
    """
    Openai-Assistant application class.
    """

    def __init__(self, api, config, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.api = api
        self.config = config
        self.assistant_name = self.config["ASSISTANT_NAME"]
        self.your_name = self.config["YOUR_NAME"]


    TITLE = "OpenAI Assistant"
    SUB_TITLE = f"{__version__}  •  Submit: Ctrl+\\  •  Quit: Ctrl+Q"
    AUTO_FOCUS = "Input_TextArea"

    # Style sheets for widgets 
    CSS = """
    DisplayPrompt {
        border: round cyan;
        background: $primary 10%;
        color: $text;
        margin: 1;        
        margin-right: 4;
        padding: 1 2 0 2;
    }

    DisplayResponse {
        border: round #f5d676;
        background: gray 10%;   
        color: $text;             
        margin: 1;      
        margin-left: 4; 
        padding: 1 2 0 2;
    }

    Input_TextArea {
        height: 20%;
    }
    """

    # Key bindings for Footer and help panel 
    BINDINGS = [
        Binding(key="ctrl+backslash", action="submit", description="Submit Input"),
        Binding(key="ctrl+q", action="quit", description="Quit"),
    ]

    # Create input widget and chat display widget
    input_area = Input_TextArea()
    chat_view = VerticalScroll()



    # Methods -------- #
    def on_mount(self) -> None:
        """
        Sets default theme.
        """
        self.theme = "flexoki"
    # End on_mount() 


    def compose(self) -> ComposeResult:
        """
        Composes UI elements.
        """
        resp_area = DisplayResponse(
            f"Hello {self.your_name}!\n\n"
            "I’m ready when you are. Type your message below.\n\n"
            "Hints: Submit with `Ctrl+Backslash`, new line with `Enter`, quit with `Ctrl+Q`.",
            border_title=self.assistant_name,
        )
        yield Header(show_clock=True)
        with self.chat_view:
            yield resp_area
        yield self.input_area
        yield Footer()
    # End compose() 


    @on(events.Key)
    async def on_key(self, event: events.Key) -> None:
        """
        The keystroke ctrl+backslash submits user input to the API,
        then displays returned result.
        """
        if event.key == "ctrl+backslash":
            text = self.input_area._on_submit()
            if not text:
                return
            try:
                if lf:
                    lf.write("\nMe:\n"+text+"\n\n")
            except Exception as e:
                print(f"[red]Error writing user input to log: {e}")
            self.input_area.load_text("Thinking...")
            await self.chat_view.mount(
                DisplayPrompt(text,
                              border_title=self.your_name))
            resp = await asyncio.to_thread(self.api.send_query, text)
            try:
                if lf:
                    lf.write("\n"+self.assistant_name+":\n"+resp+"\n\n")
                    lf.flush()
            except Exception as e:
                print(f"[red]Error writing AI response to log: {e}")
            await self.chat_view.mount(
                DisplayResponse(resp,
                                border_title=self.assistant_name))
            self.input_area.clear()
    # End on_key() 
# End Class OpenaiAssistant



if __name__ == "__main__":
    # Clear terminal
    os.system('clear')
    print(f"\n[#f5d676 b]OpenAI Assistant {__version__}[/]\n")
    print("[green]Initialising settings and backend...[/]\n")

    # Get current date and time
    now = datetime.now()
    # Format as '9 June 2025 9:52pm'
    tstamp = now.strftime('%-d %B %Y %-I:%M%p').lower()

    ## Some global definitions
    # Define home directory and config paths
    homedir     = str(Path.home()) + "/"
    CONFIG_DIR  = Path(homedir) / ".openai"
    CONFIG_PATH = CONFIG_DIR / "settings.py"
    logfile = homedir + ".openai/chat_log.txt"

    try:
        # CLI flags
        parser = argparse.ArgumentParser(
            prog="openai-assistant",
            description="Terminal client for the OpenAI Assistants API",
        )
        parser.add_argument(
            "--no-upload",
            action="store_true",
            help="Do not upload ~/.openai/chat_log.txt on startup",
        )
        parser.add_argument(
            "--reset-assistant",
            action="store_true",
            help="Ignore and clear ASSISTANT_ID in settings before startup",
        )
        parser.add_argument(
            "--reset-store",
            action="store_true",
            help="Ignore and clear VECTOR_STORE_ID in settings before startup",
        )
        parser.add_argument("--debug-api", action="store_true", help="Enable DEBUG level API logging to ~/.openai/api.log")
        args = parser.parse_args()
        # Get and load  settings, prompt for missing settings
        settings = load_settings()
        # Apply resets if requested
        if args.reset_assistant:
            settings["ASSISTANT_ID"] = ""
            try:
                write_setting("ASSISTANT_ID", "")
                print("Reset ASSISTANT_ID in settings.")
            except Exception:
                pass
        if args.reset_store:
            settings["VECTOR_STORE_ID"] = ""
            try:
                write_setting("VECTOR_STORE_ID", "")
                print("Reset VECTOR_STORE_ID in settings.")
            except Exception:
                pass
        config_app()

        # Configure API logger
        api_logfile = homedir + ".openai/api.log"
        api_logger = logging.getLogger("openai_assistant.api")
        api_logger.setLevel(logging.DEBUG if args.debug_api else logging.INFO)
        handler = TimedRotatingFileHandler(api_logfile, when="midnight", backupCount=7, encoding="utf-8")
        handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
        if not any(getattr(h, "baseFilename", None) == handler.baseFilename for h in api_logger.handlers):
            api_logger.addHandler(handler)
        api_logger.info("startup: settings initialised")


        # Open log file in append mode
        lf = open(logfile, 'a', encoding='utf-8')

        # Initialise OpenAI client
        api = Openai_API(settings, logger=api_logger)
        # Log config summary (no secrets)
        try:
            api_logger.info("config: model="+str(settings.get('MODEL'))+" temp="+str(settings.get('TEMP'))+" assistant_id="+("yes" if settings.get('ASSISTANT_ID') else "no")+" vector_store_id="+("yes" if settings.get('VECTOR_STORE_ID') else "no"))
        except Exception:
            pass

        # Set up configuration and upload chat_log.txt
        upload = api.setup(upload_log=(not args.no_upload))  # All CLI prompts and setup happen here
        status = upload.status.strip()
        if status == "cancelled":
            print("Skipping chat log upload.")
        elif status == "completed":
            print(f"Uploaded [#d5d676]{logfile}[/]\n")
        elif status == "failed":
            print(f"Upload of [red]{logfile}[/] failed!\n")
        # a little time to read msg
        sleep(3)

        # Now launch the TUI, passing the API and settings objects
        app = OpenaiAssistant(api, settings)

        # Write timestamp to log file for session date
        lf.write(f"\nSession time stamp: {tstamp}\n")

        app.run()
        lf.close()
    except Exception as e:
        print(f"[red]Caught:[/] {e}")
